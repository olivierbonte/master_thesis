{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OpenEO: Sentinel 1, $\\sigma_0$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Connection to VITO backend for cloud computing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openeo\n",
    "import geopandas as gpd\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pickle\n",
    "import xarray as xr\n",
    "import rioxarray\n",
    "import hvplot.xarray\n",
    "import hvplot.dask\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import time \n",
    "connection = openeo.connect(\"openeo.vito.be\").authenticate_oidc()\n",
    "pad = Path(os.getcwd())\n",
    "if pad.name != \"Python\":\n",
    "    pad_correct = Path(\"../../Python\")\n",
    "    os.chdir(pad_correct)\n",
    "#set all of the parameters below to True to execute cloud computing and downloading    \n",
    "overwrite = False\n",
    "read = True\n",
    "job_exec = False\n",
    "download = True\n",
    "write_out = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load in the Shapefile of the Zwalm in EPSG:4326"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('data/Zwalm_shape/zwalm_shapefile_emma.shp'):\n",
    "    %run \"preprocessing_files/shapefile_conversion.py\"   \n",
    "    print('Preprocessing script of Zwalm shapefile has run')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shape_zwalm = gpd.read_file('data/Zwalm_shape/zwalm_shapefile_emma.shp')\n",
    "shape_zwalm.plot()\n",
    "extent = shape_zwalm.total_bounds\n",
    "print(extent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#connection.list_collections()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#connection.describe_collection('SENTINEL1_GRD')\n",
    "connection.describe_collection('S1_GRD_SIGMA0_ASCENDING')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting the temporal extent in to 1 year at a time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temporal_extent = [\"2015-06-07\", \"2022-11-05\"]\n",
    "list_temp_extent = []\n",
    "list_temp_extent.append([temporal_extent[0],\"2015-12-31\"])\n",
    "years = np.arange(2016,2023)\n",
    "for year in np.arange(2016,2023):\n",
    "    if year == 2022:\n",
    "        #print([str(year)+\"-01-01\",temporal_extent[1]])\n",
    "        list_temp_extent.append([str(year)+\"-01-01\",temporal_extent[1]])\n",
    "    else:\n",
    "        #print([str(year)+\"-01-01\",str(year)+ \"-12-31\"])\n",
    "        list_temp_extent.append([str(year)+\"-01-01\",str(year)+ \"-12-31\"])\n",
    "print(list_temp_extent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ascending orbit(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collection = 'S1_GRD_SIGMA0_ASCENDING' #Ground Range Detected\n",
    "spatial_extent = {'west':extent[0],'east':extent[2],'south':extent[1],'north':extent[3]}\n",
    "bands = [\"VV\",\"VH\",\"angle\"] #enkel in deze geÃ¯nteresseerd (add VH: 24/02/2022)\n",
    "properties = {\n",
    "    'sat:orbit_state': lambda od: od == \"ASCENDING\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "years = np.arange(2015,2023)\n",
    "job_title_list = []\n",
    "job_id_list = []\n",
    "if job_exec:\n",
    "    for i, temporal_extent in enumerate(list_temp_extent):\n",
    "        s1a = connection.load_collection(\n",
    "            collection_id = collection,\n",
    "            spatial_extent= spatial_extent,\n",
    "            temporal_extent = temporal_extent,\n",
    "            bands = bands\n",
    "        )\n",
    "        s1a = s1a.mask_polygon(shape_zwalm['geometry'].values[0])\n",
    "        job_title = \"s1_a_terrascope-\" +  str(years[i])\n",
    "        job_title_list.append(job_title)\n",
    "        job_s1a = s1a.create_job(title = job_title, out_format= 'NetCDF')\n",
    "        job_s1a_id = job_s1a.job_id\n",
    "        if job_s1a_id:\n",
    "            print(\"Batch job created with id: \",job_s1a_id)\n",
    "            job_s1a.start_job()\n",
    "            job_id_list.append(job_s1a_id)\n",
    "        else:\n",
    "            print(\"Error! Job ID is None\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('data/s0_OpenEO/ascending'):\n",
    "    os.makedirs('data/s0_OpenEO/ascending')\n",
    "if download:\n",
    "    for i,job_id in enumerate(job_id_list):\n",
    "        job_connection = connection.job(job_id)\n",
    "        results = job_connection.get_results()\n",
    "        name_netcdf = job_title_list[i] + '.nc'\n",
    "        filepath = \"data/s0_OpenEO/ascending/\" + name_netcdf\n",
    "        print(filepath)\n",
    "        while job_connection.status() != 'finished':\n",
    "            time.sleep(30)\n",
    "            if job_connection.status() == 'error':\n",
    "                raise ChildProcessError(job_id + 'has encountered an error, check why batch job failed')\n",
    "            if job_connection.status() == 'canceled':\n",
    "                        raise ChildProcessError(job_id + 'has been canceled')\n",
    "        results.download_file(filepath)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in the downloaded data! \n",
    "- scale and offset from https://docs.terrascope.be/DataProducts/Sentinel-1/references/VITO_S1_sigma0_GRD.pdf "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1_xr_asc = xr.open_mfdataset('data/s0_OpenEO/ascending/*.nc', decode_coords=\"all\") #automatically chuncked!\n",
    "#s1_xr_asc['VV_db'] = 10 * np.log10(s1_xr_asc['VV'])\n",
    "scale = 0.0005\n",
    "offset = 29\n",
    "s1_xr_asc['angle']  = s1_xr_asc['angle']*scale + offset   \n",
    "s1_xr_asc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now only select the values for which sufficient data is present. First check amount of data in a full image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1_xr_asc_plot = s1_xr_asc.copy()\n",
    "s1_xr_asc_plot['VV_db'] = 10*np.log10(s1_xr_asc_plot['VV'])\n",
    "s1_xr_asc_plot['VV_db'].isel(t=0).plot() #example of a full image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1_xr_asc['angle'].isel(t=0).plot()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xr_shape = s1_xr_asc['VH'].shape\n",
    "print('Shape of the ascending orbits: ' + str(xr_shape))\n",
    "nr_pixels = xr_shape[1]*xr_shape[2]\n",
    "print('Number of pixels per timestamp: ' + str(nr_pixels))\n",
    "nancount = np.sum(np.isnan(s1_xr_asc['VV'].isel(t=0))).values\n",
    "print('Number of nan-pixels for a full image: ' + str(nancount))\n",
    "nan_cutoff = nancount/nr_pixels\n",
    "print('Percentage of nan-pixels in a full image: ' + str(nan_cutoff*100) + '%')\n",
    "#add 5% as safety margin to cutoff\n",
    "nan_cutoff = nan_cutoff + 0.05"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xr_shape = s1_xr_asc['VV'].shape\n",
    "print('Shape of the ascending orbits: ' + str(xr_shape))\n",
    "nr_pixels = xr_shape[1]*xr_shape[2]\n",
    "print('Number of pixels per timestamp: ' + str(nr_pixels))\n",
    "nancount = np.sum(np.isnan(s1_xr_asc['VV'].isel(t=0))).values\n",
    "print('Number of nan-pixels for a full image: ' + str(nancount))\n",
    "nan_cutoff = nancount/nr_pixels\n",
    "print('Percentage of nan-pixels in a full image: ' + str(nan_cutoff*100) + '%')\n",
    "#add 5% as safety margin to cutoff\n",
    "nan_cutoff = nan_cutoff + 0.05"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the goal is to select the orbits that have a full view of the Zwalm, filtering on VV and VH is applied. If there are differences, only frames will be chosen where VV and VH are both in full image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nr_timestemps_ascending = xr_shape[0]\n",
    "bool_full_image = []\n",
    "for i in range(nr_timestemps_ascending):\n",
    "    VV_ds = s1_xr_asc['VV'].isel(t=i)\n",
    "    temp_nancount = np.sum(np.isnan(VV_ds)).values\n",
    "    nan_frac = temp_nancount/nr_pixels\n",
    "    if nan_frac > nan_cutoff:\n",
    "        bool_full_image.append(0)\n",
    "    else:\n",
    "        bool_full_image.append(1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Repeat for VH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bool_full_image_VH = []\n",
    "for i in range(nr_timestemps_ascending):\n",
    "    VV_ds = s1_xr_asc['VH'].isel(t=i)\n",
    "    temp_nancount = np.sum(np.isnan(VV_ds)).values\n",
    "    nan_frac = temp_nancount/nr_pixels\n",
    "    if nan_frac > nan_cutoff:\n",
    "        bool_full_image_VH.append(0)\n",
    "    else:\n",
    "        bool_full_image_VH.append(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not bool_full_image_VH == bool_full_image:\n",
    "    pos_full_VH = np.where(bool_full_image_VH)[0].tolist()\n",
    "    bool_full_image_np = np.array(bool_full_image)\n",
    "    bool_full_image_np[pos_full_VH] = 0\n",
    "    bool_full_image = bool_full_image_np.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_full = np.where(bool_full_image)[0].tolist()\n",
    "print(pos_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add orbit direction\n",
    "da = xr.DataArray(\n",
    "    data = np.repeat('ascending',nr_timestemps_ascending),\n",
    "    dims = ['t'],\n",
    "    coords = dict(t = s1_xr_asc['t'].values)\n",
    ")\n",
    "s1_xr_asc['Orbitdirection'] = da"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1_xr_asc_full = s1_xr_asc.isel(t = pos_full)\n",
    "s1_xr_asc_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = 10*np.log10(s1_xr_asc_full['VV'])\n",
    "temp.hvplot.image('x','y', geo = True, crs = 32631, tiles = 'OSM', cmap = 'bwr', width = 400, rasterize = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Descending orbit(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collection = \"S1_GRD_SIGMA0_DESCENDING\"\n",
    "years = np.arange(2015,2023)\n",
    "job_title_list_d = []\n",
    "job_id_list_d = []\n",
    "if job_exec:\n",
    "    for i, temporal_extent in enumerate(list_temp_extent):\n",
    "        s1d = connection.load_collection(\n",
    "            collection_id = collection,\n",
    "            spatial_extent= spatial_extent,\n",
    "            temporal_extent = temporal_extent,\n",
    "            bands = bands\n",
    "        )\n",
    "        s1d = s1d.mask_polygon(shape_zwalm['geometry'].values[0])\n",
    "        job_title = \"s1_d_terrascope-\" +  str(years[i])\n",
    "        job_title_list_d.append(job_title)\n",
    "        job_s1d = s1d.create_job(title = job_title, out_format= 'NetCDF')\n",
    "        job_s1d_id = job_s1d.job_id\n",
    "        if job_s1d_id:\n",
    "            print(\"Batch job created with id: \",job_s1d_id)\n",
    "            job_s1d.start_job()\n",
    "            job_id_list_d.append(job_s1d_id)\n",
    "        else:\n",
    "            print(\"Error! Job ID is None\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if overwrite:\n",
    "    with open('data/S0_OpenEO/s1_d_job_id_list.pickle', 'wb') as handle:\n",
    "        pickle.dump(job_id_list_d, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    with open('data/S0_OpenEO/s1_d_job_title_list.pickle', 'wb') as handle:\n",
    "        pickle.dump(job_title_list_d, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if read:\n",
    "    job_id_list_d = pickle.load(open('data/S0_OpenEO/s1_d_job_id_list.pickle', \"rb\"))\n",
    "    job_title_list_d = pickle.load(open('data/S0_OpenEO/s1_d_job_title_list.pickle', \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('data/s0_OpenEO/descending'):\n",
    "    os.makedirs('data/s0_OpenEO/descending')\n",
    "if download:\n",
    "    for i,job_id in enumerate(job_id_list_d):\n",
    "        job_connection = connection.job(job_id)\n",
    "        results = job_connection.get_results()\n",
    "        name_netcdf = job_title_list_d[i] + '.nc'\n",
    "        filepath = \"data/s0_OpenEO/descending/\" + name_netcdf\n",
    "        print(filepath)\n",
    "        while job_connection.status() != 'finished':\n",
    "            time.sleep(30)\n",
    "            if job_connection.status() == 'error':\n",
    "                raise ChildProcessError(job_id + 'has encountered an error, check why batch job failed')\n",
    "            if job_connection.status() == 'canceled':\n",
    "                        raise ChildProcessError(job_id + 'has been canceled')\n",
    "        results.download_file(filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analogous processing as for ascending"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1_xr_desc = xr.open_mfdataset('data/s0_OpenEO/descending/*.nc', decode_coords=\"all\") #automatically chuncked!\n",
    "# s1_xr_desc['VV_db'] = 10 * np.log10(s1_xr_desc['VV'])\n",
    "s1_xr_desc['angle']  = s1_xr_desc['angle']*scale + offset   \n",
    "display(s1_xr_desc)\n",
    "xr_shape_desc = s1_xr_desc['VV'].shape\n",
    "#only full images selected\n",
    "nr_timestemps_descending = xr_shape_desc[0]\n",
    "#VV\n",
    "bool_full_image = []\n",
    "for i in range(nr_timestemps_descending):\n",
    "    VV_ds = s1_xr_desc['VV'].isel(t=i)\n",
    "    temp_nancount = np.sum(np.isnan(VV_ds)).values\n",
    "    nan_frac = temp_nancount/nr_pixels\n",
    "    if nan_frac > nan_cutoff:\n",
    "        bool_full_image.append(0)\n",
    "    else:\n",
    "        bool_full_image.append(1)\n",
    "#VH\n",
    "bool_full_image_VH = []\n",
    "for i in range(nr_timestemps_ascending):\n",
    "    VV_ds = s1_xr_asc['VH'].isel(t=i)\n",
    "    temp_nancount = np.sum(np.isnan(VV_ds)).values\n",
    "    nan_frac = temp_nancount/nr_pixels\n",
    "    if nan_frac > nan_cutoff:\n",
    "        bool_full_image_VH.append(0)\n",
    "    else:\n",
    "        bool_full_image_VH.append(1)\n",
    "if not bool_full_image_VH == bool_full_image:\n",
    "    pos_full_VH = np.where(bool_full_image_VH)[0].tolist()\n",
    "    bool_full_image_np = np.array(bool_full_image)\n",
    "    bool_full_image_np[pos_full_VH] = 0\n",
    "    bool_full_image = bool_full_image_np.tolist()\n",
    "pos_full = np.where(bool_full_image)[0].tolist()\n",
    "#add orbit direction\n",
    "da = xr.DataArray(\n",
    "    data = np.repeat('descending',nr_timestemps_descending),\n",
    "    dims = ['t'],\n",
    "    coords = dict(t = s1_xr_desc['t'].values)\n",
    ")\n",
    "s1_xr_desc['Orbitdirection'] = da\n",
    "\n",
    "s1_xr_desc_full = s1_xr_desc.isel(t= pos_full)\n",
    "display(s1_xr_desc_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = 10*np.log10(s1_xr_desc_full['VV'])\n",
    "temp.hvplot.image('x','y', geo = True, crs = 32631, tiles = 'OSM', cmap = 'bwr', width = 400, rasterize = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combining orbits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1_xr_asc_full.attrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#s1_xr_full = xr.combine_by_coords([s1_xr_asc_full,s1_xr_desc_full], coords = ['x','y'])\n",
    "s1_xr_full = xr.merge([s1_xr_asc_full, s1_xr_desc_full])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(s1_xr_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = 10 * np.log10(s1_xr_full['VV'])\n",
    "temp.hvplot.image('x','y', geo = True, crs = 32631, tiles = 'OSM', cmap = 'bwr', frame_width = 400, rasterize = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if write_out:\n",
    "    s1_xr_full.to_netcdf('data/S0_OpenEO/S0_zwalm.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "toc-autonumbering": true,
  "vscode": {
   "interpreter": {
    "hash": "a6b8480143e45034b950661dc46ed3131c1d39c9fcb21ab7eff1dd297a31067d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
