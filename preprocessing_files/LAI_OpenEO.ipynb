{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OpenEO: LAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openeo\n",
    "import geopandas as gpd\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import hvplot.xarray\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import os\n",
    "connection = openeo.connect(\"openeo.vito.be\").authenticate_oidc()\n",
    "pad = Path(os.getcwd())\n",
    "if pad.name != \"Python\":\n",
    "    pad_correct = Path(\"../../Python\")\n",
    "    os.chdir(pad_correct)\n",
    "from functions.pre_processing import pre_processing_pipeline\n",
    "\n",
    "#set all to True to process \n",
    "job_excec = False\n",
    "download_exec = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shape_zwalm = gpd.read_file('data/Zwalm_shape/zwalm_shapefile_emma.shp')\n",
    "shape_zwalm.plot()\n",
    "extent = shape_zwalm.total_bounds\n",
    "print(extent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#connection.list_collections()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#connection.describe_collection(\"PROBAV_L3_S5_TOC_100M\")\n",
    "connection.describe_collection('CGLS_LAI300_V1_GLOBAL')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://land.copernicus.eu/global/products/lai belangrijk: The physical values (PV) are derived from the digital number (DN) using the relation: PV = Scaling * DN + Offset. Some specific values are used: 255 for missing pixels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collection = \"CGLS_LAI300_V1_GLOBAL\"\n",
    "spatial_extent = {'west':extent[0],'east':extent[2],'south':extent[1],'north':extent[3]}\n",
    "temporal_extent = [\"2014-11-18\", \"2022-11-05\"] \n",
    "#bands = [\"NDVI\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_temp_extent = []\n",
    "list_temp_extent.append([temporal_extent[0],\"2014-12-31\"])\n",
    "import numpy as np\n",
    "for year in np.arange(2015,2023):\n",
    "    if year == 2022:\n",
    "        #print([str(year)+\"-01-01\",temporal_extent[1]])\n",
    "        list_temp_extent.append([str(year)+\"-01-01\",temporal_extent[1]])\n",
    "    else:\n",
    "        #print([str(year)+\"-01-01\",str(year)+ \"-12-31\"])\n",
    "        list_temp_extent.append([str(year)+\"-01-01\",str(year)+ \"-12-31\"])\n",
    "print(list_temp_extent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "years = np.arange(2014,2023)\n",
    "job_title_list = []\n",
    "job_id_list = []\n",
    "if job_excec:\n",
    "    for i, temporal_extent in enumerate(list_temp_extent):\n",
    "        probav = connection.load_collection(\n",
    "            collection_id = collection,\n",
    "            spatial_extent= spatial_extent,\n",
    "            temporal_extent = temporal_extent#,\n",
    "            #bands = bands\n",
    "        )\n",
    "        probav = probav.mask_polygon(shape_zwalm['geometry'].values[0])\n",
    "        job_title = \"probav-\" +  str(years[i])\n",
    "        job_title_list.append(job_title)\n",
    "        job_probav = probav.create_job(title = job_title, out_format= 'NetCDF')\n",
    "        job_probav_id = job_probav.job_id\n",
    "        if job_probav_id:\n",
    "            print(\"Batch job created with id: \",job_probav_id)\n",
    "            job_probav.start_job()\n",
    "            job_id_list.append(job_probav_id)\n",
    "        else:\n",
    "            print(\"Error! Job ID is None\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# job_id_list\n",
    "# with open('temp/probva_job_id_list.pkl', 'wb') as handle:\n",
    "#     pickle.dump(job_id_list, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# job_id_list = pickle.load(open(\"temp/probva_job_id_list.pkl\", \"rb\"))\n",
    "if download_exec:\n",
    "    for i,job_id in enumerate(job_id_list):\n",
    "        job_connection = connection.job(job_id)\n",
    "        results = job_connection.get_results()\n",
    "        name_netcdf = job_title_list[i] + '.nc'\n",
    "        filepath = \"data/LAI/\" + name_netcdf\n",
    "        print(filepath)\n",
    "        results.download_file(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_id_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check dataset out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LAI_xr = xr.open_mfdataset('data/LAI/*.nc', decode_coords = 'all')\n",
    "LAI_xr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "uint 8 => 0-255 only! PV = Scaling * DN + Offset. https://land.copernicus.eu/global/products/lai  \n",
    "scaling = 1/30\n",
    "offset = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LAI_xr_masked = LAI_xr.where(LAI_xr['LAI'] != 255) #255 = reserverd for No value!\n",
    "LAI_xr_masked['LAI'] = LAI_xr_masked['LAI'].astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaling = 1/30\n",
    "offset = 0\n",
    "LAI_xr_masked['LAI_pv'] = LAI_xr_masked['LAI']*scaling + offset\n",
    "LAI_xr_masked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LAI_xr_masked['LAI'].hvplot.image('x','y',geo = True, frame_width = 350, tiles = 'OSM',cmap = 'cividis')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Give flag to dates without full data availability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#determine how many pixels for +- full image\n",
    "xr_shape = LAI_xr_masked['LAI'].shape\n",
    "nr_pixels = xr_shape[1]*xr_shape[2]\n",
    "print('Total number of pixels: ' + str(nr_pixels))\n",
    "nr_nan_full = np.sum(np.isnan(LAI_xr_masked['LAI'].isel(t=0))).values\n",
    "print('Numer of nan pixels full image: ' + str(nr_nan_full))\n",
    "nan_cutoff = nr_nan_full/nr_pixels\n",
    "print('Percentage nan pixels full imgage: ' + str(nan_cutoff*100) + '%')\n",
    "nan_cutoff = nan_cutoff + 0.05 #add 5% margin before classifying as not full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nr_timestemps = xr_shape[0]\n",
    "bool_full_image = []\n",
    "for i in range(nr_timestemps):\n",
    "    LAI_ds = LAI_xr_masked['LAI'].isel(t=i)\n",
    "    temp_nancount = np.sum(np.isnan(LAI_ds)).values\n",
    "    nan_frac = temp_nancount/nr_pixels\n",
    "    if nan_frac > nan_cutoff:\n",
    "        bool_full_image.append(0)\n",
    "    else:\n",
    "        bool_full_image.append(1)\n",
    "pos_full = np.where(bool_full_image)[0].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "da = xr.DataArray(\n",
    "    data = bool_full_image,\n",
    "    dims = ['t'],\n",
    "    coords = dict(t = LAI_xr_masked['t'].values)\n",
    ")\n",
    "da = da.astype(np.int8)\n",
    "LAI_xr_masked['bool_full_image'] = da\n",
    "LAI_xr_masked"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "seperate xarray with only full images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LAI_xr_masked_full = LAI_xr_masked.isel(t = pos_full)\n",
    "LAI_xr_masked_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LAI_xr_masked.to_netcdf('data/LAI/LAI_cube_Zwalm.nc', mode = 'w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Average trends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_trends = LAI_xr_masked['LAI_pv'].mean(dim =['x','y'])\n",
    "average_trends_full = LAI_xr_masked_full['LAI_pv'].mean(dim = ['x','y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(average_trends)\n",
    "fig, (ax, ax2) = plt.subplots(1,2, figsize = (14,8))\n",
    "average_trends.plot(ax = ax, marker = 'o')\n",
    "LAI_xr_masked['bool_full_image'].plot(ax = ax)\n",
    "ax.set_ylim([0,4])\n",
    "ax.set_title('All timesteps included')\n",
    "\n",
    "average_trends_full.plot(ax = ax2, marker = 'o')\n",
    "LAI_xr_masked_full['bool_full_image'].plot(ax = ax2)\n",
    "ax2.set_ylim([0,4])\n",
    "ax2.set_title('Only timestep with full images included')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preference for only full images, better trend?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6 | packaged by conda-forge | (main, Aug 22 2022, 20:30:19) [MSC v.1929 64 bit (AMD64)]"
  },
  "vscode": {
   "interpreter": {
    "hash": "a6b8480143e45034b950661dc46ed3131c1d39c9fcb21ab7eff1dd297a31067d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
