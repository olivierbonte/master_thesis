{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time switch: include last 2 years in training, first 2 years as test\n",
    "\n",
    "Rationale: the last 2 years of testing data contain highs and lows in C* not earlier seen in the trainig data. Therefore, it is hypothesised that if these were to be included in the training, better test performances might be reached."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "pad = Path(os.getcwd())\n",
    "if pad.name == \"ml_observation_operator\":\n",
    "    pad_correct = pad.parent\n",
    "    os.chdir(pad_correct)\n",
    "%run \"ml_observation_operator/data_load_in.py\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ML_data_pad = Path(\"data/Zwalm_data/ML_data\")\n",
    "X_full_all = pd.read_pickle(ML_data_pad/\"X_full_all.pkl\")\n",
    "\n",
    "y_train = pd.read_pickle(ML_data_pad/\"y_train_bis.pkl\")\n",
    "y_test = pd.read_pickle(ML_data_pad/\"y_test_bis.pkl\")\n",
    "y_full = pd.read_pickle(ML_data_pad/\"y_full.pkl\")\n",
    "\n",
    "X_train = pd.read_pickle(ML_data_pad/\"X_train_bis.pkl\")\n",
    "X_test = pd.read_pickle(ML_data_pad/\"X_test_bis.pkl\")\n",
    "X_full = pd.read_pickle(ML_data_pad/\"X_full.pkl\")\n",
    "\n",
    "X_train_small = pd.read_pickle(ML_data_pad/\"X_train_small_bis.pkl\")\n",
    "X_test_small = pd.read_pickle(ML_data_pad/\"X_test_small_bis.pkl\")\n",
    "X_full_small = pd.read_pickle(ML_data_pad/\"X_full_small.pkl\")\n",
    "\n",
    "Cstar = pd.read_pickle(ML_data_pad/\"Cstar.pkl\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop delta t "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.drop('delta_t',axis = 1)\n",
    "X_test = X_test.drop('delta_t',axis = 1)\n",
    "X_full = X_full.drop('delta_t',axis = 1)\n",
    "display(X_full.head())\n",
    "\n",
    "X_train_small = X_train_small.drop('delta_t',axis = 1)\n",
    "X_test_small = X_test_small.drop('delta_t',axis = 1)\n",
    "X_full_small = X_full_small.drop('delta_t',axis = 1)\n",
    "display(X_full_small.head())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load in used packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import random as python_random\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import models, layers\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, RidgeCV,   LassoCV \n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import RBF, WhiteKernel\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from functions.ml_utils import general_sklearn_model, validation_loop, full_training_loop\n",
    "from functions.pre_processing import reshape_data, reshaped_to_train_test\n",
    "from functions.plotting_functions import ensemble_plot\n",
    "SEED = 1234\n",
    "\n",
    "python_random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rasterio"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run \"ml_observation_operator/data_load_in.py\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ML_data_pad = Path(\"data/Zwalm_data/ML_data\")\n",
    "X_full_all = pd.read_pickle(ML_data_pad/\"X_full_all.pkl\")\n",
    "\n",
    "y_train = pd.read_pickle(ML_data_pad/\"y_train_bis.pkl\")\n",
    "y_test = pd.read_pickle(ML_data_pad/\"y_test_bis.pkl\")\n",
    "y_full = pd.read_pickle(ML_data_pad/\"y_full.pkl\")\n",
    "\n",
    "X_train = pd.read_pickle(ML_data_pad/\"X_train_bis.pkl\")\n",
    "X_test = pd.read_pickle(ML_data_pad/\"X_test_bis.pkl\")\n",
    "X_full = pd.read_pickle(ML_data_pad/\"X_full.pkl\")\n",
    "\n",
    "X_train_small = pd.read_pickle(ML_data_pad/\"X_train_small_bis.pkl\")\n",
    "X_test_small = pd.read_pickle(ML_data_pad/\"X_test_small_bis.pkl\")\n",
    "X_full_small = pd.read_pickle(ML_data_pad/\"X_full_small.pkl\")\n",
    "\n",
    "Cstar = pd.read_pickle(ML_data_pad/\"Cstar.pkl\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop the delta t feature again: only relevant for LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.drop('delta_t',axis = 1)\n",
    "X_test = X_test.drop('delta_t',axis = 1)\n",
    "X_full = X_full.drop('delta_t',axis = 1)\n",
    "display(X_full.head())\n",
    "\n",
    "X_train_small = X_train_small.drop('delta_t',axis = 1)\n",
    "X_test_small = X_test_small.drop('delta_t',axis = 1)\n",
    "X_full_small = X_full_small.drop('delta_t',axis = 1)\n",
    "display(X_full_small.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A normalised version for when needed\n",
    "X_scaler = StandardScaler()\n",
    "X_scaler.fit(X_train)\n",
    "X_full_norm = X_scaler.transform(X_full)\n",
    "\n",
    "y_scaler = StandardScaler()\n",
    "y_scaler.fit(y_train.values.reshape(-1,1))\n",
    "y_full_norm = y_scaler.transform(y_full.values.reshape(-1,1))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linreg, r2_train, r2_test, fig, ax = general_sklearn_model(LinearRegression(),\n",
    "    X_train,X_test, y_train.values.reshape(-1,1), y_test.values.reshape(-1,1), X_train.index,X_test.index, Cstar,normalisation = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linreg.coef_"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop time feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linreg_drop, r2_train, r2_test, fig, ax = general_sklearn_model(\n",
    "     LinearRegression(), X_train.drop(['year_sin','year_cos'], axis = 1),\n",
    "     X_test.drop(['year_sin','year_cos'], axis = 1), \n",
    "     y_train.values.reshape(-1,1),y_test.values.reshape(-1,1),X_train.index, X_test.index, Cstar)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ridge regression on window"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best model structure for ridge regresion on window (cf `simple_models.ipynb'). But use a different alpha!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pad = Path('data/ml_obs_op_data/ridge/window')\n",
    "hyperparam_best_nt = pd.read_csv(pad/'best_hyperparam.csv')\n",
    "model_name = hyperparam_best_nt['model'].values[0]\n",
    "alpha = hyperparam_best_nt['alpha'].values[0]\n",
    "seq_length = hyperparam_best_nt['seq_length'].values[0]\n",
    "time_goniometr = hyperparam_best_nt['time_bool'].values[0]\n",
    "forest = hyperparam_best_nt['forest_bool'].values[0]\n",
    "X_temp_train = X_train.copy()\n",
    "X_temp_test = X_test.copy()\n",
    "if not time_goniometr:\n",
    "    X_temp_train = X_temp_train.drop(['year_sin','year_cos'],axis = 1)\n",
    "    X_temp_test = X_temp_test.drop(['year_sin','year_cos'],axis = 1)\n",
    "if not forest:\n",
    "    X_temp_train = X_temp_train.loc[:,~X_temp_train.columns.str.endswith('Forest')]\n",
    "    X_temp_test = X_temp_test.loc[:,~X_temp_test.columns.str.endswith('Forest')]\n",
    "#kf = KFold(n_splits = 5,shuffle= True, random_state = SEED)\n",
    "if model_name == 'Ridge':\n",
    "    model = RidgeCV(alphas = np.logspace(-3,3,100), cv = 5)\n",
    "elif model_name == 'Lasso':\n",
    "    model = LassoCV(alphas = np.logspace(-3,3,100), cv = 5)\n",
    "else:\n",
    "    ValueError(\"Unknown model name\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Custom window creating! Neede for correct use of \n",
    "# X_W_full, y_w_full, t_w_full= reshape_data(X_full.values, y_full.values.reshape(-1,1), X_full.index,seq_length)\n",
    "X_W_full, y_w_full, t_w_full= reshape_data(X_full_norm, y_full_norm, X_full.index,seq_length)\n",
    "#Just use reshaped_to_train_test where you train -> test and test -> train with n_train = n_test!\n",
    "n_test_og = len(y_test)\n",
    "(X_test_w, X_train_w, y_test_w, y_train_w, t_test_w, \n",
    " t_train_w) = reshaped_to_train_test(X_W_full, y_w_full, t_w_full, seq_length, n_test_og,output_dim=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_w.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "func, r2_train, r2_test, fig, ax, y_train_hat, y_test_hat = general_sklearn_model(model, X_train_w, X_test_w, y_train_w, y_test_w,\n",
    "    t_train_w, t_test_w, Cstar,normalisation = False,seq_length = seq_length,\n",
    "    print_output = False, return_predictions=True)\n",
    "fig, ax = plt.subplots()\n",
    "Cstar[X_full.index].plot(ax=ax)\n",
    "ax.plot(y_train_hat.index, y_scaler.inverse_transform(y_train_hat.values), label='Train')\n",
    "ax.plot(y_test_hat.index, y_scaler.inverse_transform(y_test_hat.values), label='Test')\n",
    "ax.legend()\n",
    "ax.set_ylabel('C* [mm]')\n",
    "print(r2_train)\n",
    "print(r2_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "func, r2_train, r2_test, fig, ax, y_train_hat, y_test_hat = general_sklearn_model(Ridge(alpha = alpha), X_train_w, X_test_w, y_train_w, y_test_w,t_train_w, t_test_w, Cstar,normalisation = False,seq_length = seq_length, return_predictions=True, print_output=False)\n",
    "fig, ax = plt.subplots()\n",
    "Cstar[X_full.index].plot(ax=ax)\n",
    "ax.plot(y_train_hat.index, y_scaler.inverse_transform(y_train_hat.values), label='Train')\n",
    "ax.plot(y_test_hat.index, y_scaler.inverse_transform(y_test_hat.values), label='Test')\n",
    "ax.legend()\n",
    "ax.set_ylabel('C* [mm]')\n",
    "print(r2_train)\n",
    "print(r2_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_test_w.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An overfit function now"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Non-linear: GP RBF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel = RBF(length_scale=1e-1, length_scale_bounds=(1e-2, 1e2)) + WhiteKernel(\n",
    "    noise_level=1, noise_level_bounds=(1e-2, 1e3) #1e-1 seems best as lower\n",
    ")\n",
    "gpr = GaussianProcessRegressor(kernel = kernel, alpha= 0, n_restarts_optimizer=100, random_state=SEED)\n",
    "gpr_for_pipe = GaussianProcessRegressor(kernel = kernel, alpha= 0, n_restarts_optimizer=100, normalize_y = True, random_state=SEED)\n",
    "gpr_pipe = make_pipeline(StandardScaler(),gpr_for_pipe) \n",
    "# normalisation can be included in general GP (easier than via normalisation in general sklearn model)\n",
    "#Pad to save to later\n",
    "pad = Path('data/ml_obs_op_data/GPR_bis')\n",
    "gpr_out, r2_train, r2_test, fig, ax = general_sklearn_model(\n",
    "     gpr_pipe, X_train, X_test, y_train, y_test, X_train.index, X_test.index, Cstar,normalisation=False, save_predictions=True, pad = pad\n",
    ")\n",
    "ax.set_title('GP RBF full datastet')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Worse performer than Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpr_out[1].kernel_"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test the ANN structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_features = X_train.shape[1]\n",
    "print(2*n_features+1) #round of to 32 for first layer\n",
    "ann_extended = models.Sequential(\n",
    "    [\n",
    "    layers.Input(shape = (n_features,)),\n",
    "    layers.Dense(32, activation = \"relu\", name = 'layer1'), #first number = dimensionality of the output space!\n",
    "    layers.Dropout(0.2),\n",
    "    layers.Dense(16, activation = \"relu\", name = 'layer2'),\n",
    "    layers.Dropout(0.2),    \n",
    "    layers.Dense(1, activation = \"linear\", name = 'layer3'),\n",
    "    ]\n",
    ")\n",
    "pad = Path('data/ml_obs_op_data/ann/extende_ann_bis')\n",
    "if not os.path.exists(pad):\n",
    "    os.makedirs(pad)\n",
    "ann_extended.summary()\n",
    "\n",
    "exec_training = True\n",
    "repeats = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_r2_val, recommended_nr_epochs = validation_loop(\n",
    "        ann_extended, repeats, X_train, X_test,y_train, y_test, Cstar,\n",
    "        exec_training,pad,epochs = 100,print_output = False,\n",
    "        verbose = 0, validation_split = 0.2, dask_bool = True)\n",
    "print(mean_r2_val); print(recommended_nr_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_r2_train, mean_r2_test, out_dict, models_list = full_training_loop(\n",
    " ann_extended, repeats,X_train, X_test,y_train,y_test, Cstar,\n",
    " exec_training, recommended_nr_epochs, pad, print_output = False,\n",
    " verbose = 0, validation_split=0.0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_std = 1\n",
    "ensemble_plot(Cstar, X_full.index, out_dict, n_std)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test the LSTM structure\n",
    "\n",
    "Skipped as of now, no indication that the changing around of time gives great benefit to non-linear models!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
