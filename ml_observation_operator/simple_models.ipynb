{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple models for the observation operator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before applying the complex LSTM model, we'll first check the performance of much simpler ML models: linear regression and ridge regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from sklearn.linear_model import LinearRegression, Ridge, RidgeCV\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "\n",
    "pad = Path(os.getcwd())\n",
    "if pad.name == \"ml_observation_operator\":\n",
    "    pad_correct = pad.parent\n",
    "    os.chdir(pad_correct)\n",
    "from functions.PDM import PDM\n",
    "\n",
    "%load_ext autoreload \n",
    "%autoreload 2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PDM\n",
    "#Forcing data\n",
    "preprocess_output_folder = Path('data/Zwalm_data/preprocess_output')\n",
    "p_zwalm = pd.read_pickle(preprocess_output_folder/'zwalm_p_thiessen.pkl')\n",
    "ep_zwalm = pd.read_pickle(preprocess_output_folder/'zwalm_ep_thiessen.pkl')\n",
    "\n",
    "#Parameterset\n",
    "param = pd.read_csv(\"data/Zwalm_PDM_parameters/p1_opt_param_mNSE_PSO_70_particles_qconst_strict.csv\", index_col = False)\n",
    "param = param.drop(param.columns[0], axis = 1)\n",
    "param\n",
    "\n",
    "#Area Zwalm\n",
    "zwalm_shape = gpd.read_file('data/Zwalm_shape/zwalm_shapefile_emma_31370.shp')\n",
    "area_zwalm_new = np.single(zwalm_shape.area[0]/10**6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Features for data-driven model\n",
    "features = pd.read_csv('data/g0_OpenEO/s1_g0_timeseries.csv', parse_dates=True)\n",
    "features = features.set_index('t')\n",
    "features.index = pd.to_datetime(features.index)\n",
    "print(features.columns)\n",
    "cols = features.columns[features.columns.str.endswith(('Pasture','Agriculture','Forest'))]\n",
    "#Make dummy variables of the orbit direction\n",
    "orb_dir_dummies = pd.get_dummies(features.Orbitdirection)\n",
    "orb_dir_dummies = orb_dir_dummies.set_index(features.index)\n",
    "features = pd.concat([features[cols],orb_dir_dummies],axis = 1)\n",
    "features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_corr = features.corr()\n",
    "features_corr.style.background_gradient(cmap = 'coolwarm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the PDM for the desired parameterset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deltat = np.array(1,dtype = np.float32) #hour\n",
    "deltat_out = np.array(24, dtype = np.float32) #daily averaging\n",
    "pd_zwalm_out_day = PDM(P = p_zwalm['P_thiessen'].values, \n",
    "    EP = ep_zwalm['EP_thiessen'].values,\n",
    "    t = p_zwalm['Timestamp'].values,\n",
    "    area = area_zwalm_new, deltat = deltat, deltatout = deltat_out ,\n",
    "    parameters = param, m = 3)\n",
    "pd_zwalm_out_day = pd_zwalm_out_day.set_index('Time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_zwalm_out_day['Cstar'].plot(title = 'C*', ylabel = '[mm]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_zwalm_out_day "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Cstar = pd_zwalm_out_day['Cstar']\n",
    "Cstar.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split up dataset in training and validation part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1_features = features.index[0]\n",
    "print('day 1 SAR data: ' + str(t1_features))\n",
    "tend_features = features.index[-1]\n",
    "print('last day SAR data: ' + str(tend_features))\n",
    "nr_days = tend_features - t1_features\n",
    "nr_years = nr_days.total_seconds()/(3600*24*365.25)\n",
    "print('years of SAR data: ' + str(nr_years))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take 5.5 years of training data and the remaining 2 as validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tend_calibration = pd.Timestamp(datetime(year = 2020, month = 12, day = 31))\n",
    "tbegin_validation = pd.Timestamp(datetime(year = 2021, month = 1, day = 1))\n",
    "\n",
    "print('Calibration period: ' + str(t1_features) + ' until ' + str(tend_calibration))\n",
    "print('Validation period: ' + str(tbegin_validation) + ' until ' + str(tend_features))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = features[t1_features:tend_calibration]\n",
    "X_test = features[tbegin_validation:tend_features]\n",
    " \n",
    "#select only on days with available training data! \n",
    "y_train = Cstar[X_train.index]\n",
    "y_test = Cstar[X_test.index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Idea of linear regression as observation operator alreayd applied in Auber(cf. [obsidian](C:\\Users\\olivi\\Documents\\ob_obsidian\\DA\\Aubert_SM_DA_in_conceptual_model.md) and https://www.sciencedirect.com/science/article/pii/S0022169403002294?via%3Dihub )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Include forest in the equation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://en.wikipedia.org/wiki/Coefficient_of_determination#Adjusted_R2 \n",
    "\n",
    "Calculated adjusted $R^2$ (=$\\bar{R}^2$) from regular $R^2$ as:\n",
    "$$\n",
    "{\\displaystyle {\\bar {R}}^{2}=1-(1-R^{2}){n-1 \\over n-p}}\n",
    "$$\n",
    "\n",
    "with $n$ the number of variables  and $p$ the number parameters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LinReg = LinearRegression()\n",
    "LinReg.fit(X_train, y_train)\n",
    "y_train_hat = LinReg.predict(X_train)\n",
    "\n",
    "#Also try normalising both input and output before prediction\n",
    "LinRegnorm = make_pipeline(StandardScaler(), LinearRegression())\n",
    "scaler_y = StandardScaler()\n",
    "scaler_y.fit(y_train.values.reshape(-1, 1))\n",
    "y_train_norm = scaler_y.transform(y_train.values.reshape(-1, 1))\n",
    "y_test_norm = scaler_y.transform(y_test.values.reshape(-1, 1))\n",
    "LinRegnorm.fit(X_train, y_train_norm)\n",
    "y_train_norm_hat = LinRegnorm.predict(X_train)\n",
    "y_test_norm_hat = LinRegnorm.predict(X_test)\n",
    "\n",
    "#Trainig set performance\n",
    "mse_train = mean_squared_error(y_train, y_train_hat)\n",
    "mse_train_norm = mean_squared_error(y_train, scaler_y.inverse_transform(y_train_norm_hat))\n",
    "r2_train = r2_score(y_train, y_train_hat)\n",
    "r2_train_norm = r2_score(y_train,scaler_y.inverse_transform(y_train_norm_hat))\n",
    "n_train = X_train.shape[0]\n",
    "p = LinReg.coef_.shape[0] + 1 #+1 for the intercept\n",
    "r2_adjsted_train = 1 - (1-r2_train)*(n_train - 1)/(n_train - p)\n",
    "r2_adjsted_train_norm = 1 - (1-r2_train_norm)*(n_train - 1)/(n_train - p)\n",
    "print('RMSE on training data: ' + str(np.sqrt(mse_train)))\n",
    "print('RMSE on training data with normalisation: ' + str(np.sqrt(mse_train_norm)))\n",
    "print('R2 on training data: ' + str(r2_train))\n",
    "print('R2 on training data with normalisation: ' + str(r2_train_norm))\n",
    "print('Adjusted R2 on training data: ' + str(r2_adjsted_train))\n",
    "print('Adjusted R2 on training data with normalisation: ' + str(r2_adjsted_train_norm))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not sure how to calculate R2 adjusted on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test set performance\n",
    "y_test_hat = LinReg.predict(X_test)\n",
    "y_test_norm_hat = LinRegnorm.predict(X_test)\n",
    "mse_test = mean_squared_error(y_test, y_test_hat)\n",
    "mse_test_norm = mean_squared_error(y_test, scaler_y.inverse_transform(y_test_norm_hat))\n",
    "r2_test = r2_score(y_test, y_test_hat)\n",
    "r2_test_norm = r2_score(y_test, scaler_y.inverse_transform(y_test_norm_hat))\n",
    "print('RMSE on test data: ' + str(np.sqrt(mse_test)))\n",
    "print('RMSE on test data with normalisation: ' + str(np.sqrt(mse_test_norm)))\n",
    "print('R2 on test data: ' + str(r2_test))\n",
    "print('R2 on test data with normalisation: ' + str(r2_test_norm))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusion on normalisation: not really necessary in this case, basically no difference in performance! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coef_dict =  {}\n",
    "for i, param in enumerate(X_train.columns.to_list()):\n",
    "    coef_dict[param] = LinReg.coef_[i]\n",
    "pd_coef = pd.DataFrame(coef_dict, index =[0])\n",
    "pd_coef"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualise the predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Cstar_SAR_time = pd_zwalm_out_day.loc[features.index, 'Cstar']\n",
    "fig,ax = plt.subplots()\n",
    "Cstar_SAR_time.plot(ax = ax, ylabel = 'C* [mm]', label = 'PDM')\n",
    "plt.plot(X_train.index, y_train_hat, label = 'Train', alpha = 0.7)\n",
    "plt.plot(X_test.index, y_test_hat, label = 'Test', alpha = 0.7)\n",
    "ax.legend()\n",
    "ax.set_title('Linear regression')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ridge regression\n",
    "\n",
    "L2 normalisation. Well explained in https://scikit-learn.org/stable/modules/linear_model.html#ridge-regression-and-classification "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.RidgeCV.html automatic best hyperparamter $\\alpha$ (often called $\\lambda$) for regularisation by appyling crosss validation. cv = 5 is 5-fold cross-validation within the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge = RidgeCV(alphas = np.logspace(-3,3,100), cv = 5)\n",
    "ridge.fit(X_train, y_train)\n",
    "y_train_hat_ridge = ridge.predict(X_train)\n",
    "\n",
    "#Trainig set performance\n",
    "mse_train_ridge = mean_squared_error(y_train, y_train_hat_ridge)\n",
    "r2_train_ridge = r2_score(y_train, y_train_hat_ridge)\n",
    "n_train = X_train.shape[0]\n",
    "p = ridge.coef_.shape[0] + 1 #+1 for the intercept\n",
    "r2_adjsted_train_ridge = 1 - (1-r2_train_ridge)*(n_train - 1)/(n_train - p)\n",
    "print('RMSE on training data: ' + str(np.sqrt(mse_train_ridge)))\n",
    "print('R2 on training data: ' + str(r2_train))\n",
    "print('Adjusted R2 on training data: ' + str(r2_adjsted_train_ridge))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test set performance\n",
    "y_test_hat_ridge = ridge.predict(X_test)\n",
    "mse_test_ridge = mean_squared_error(y_test, y_test_hat_ridge)\n",
    "r2_test_ridge = r2_score(y_test, y_test_hat_ridge)\n",
    "print('RMSE on test data ridge regression: ' + str(np.sqrt(mse_test_ridge)))\n",
    "print('R2 on test data ridge regression: ' + str(r2_test_ridge))\n",
    "print('RMSE on test data linear regression: ' + str(np.sqrt(mse_test)))\n",
    "print('R2 on test data linear regression: ' + str(r2_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Very minimal differences with normal linear regression! So very little regularisation needed!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots()\n",
    "Cstar_SAR_time.plot(ax = ax, ylabel = 'C* [mm]', label = 'PDM')\n",
    "plt.plot(X_train.index, y_train_hat_ridge, label = 'Train', alpha = 0.7)\n",
    "plt.plot(X_test.index, y_test_hat_ridge, label = 'Test', alpha = 0.7)\n",
    "ax.legend()\n",
    "ax.set_title('Ridge regression')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Leaving out all forest data lead to significantly worse performance on preliminary test (mainly due to less degrees of freedom I believe)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector regression"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://scikit-learn.org/stable/modules/svm.html#svm-regression\n",
    "\n",
    "\n",
    "C and epsilon to be optimised => cross validation ideally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svr_nonlin = make_pipeline(StandardScaler(), SVR(kernel = 'rbf', C = 100, epsilon = 0.2))\n",
    "svr_nonlin.fit(X_train, y_train)\n",
    "y_train_SVR = svr_nonlin.predict(X_train)\n",
    "r2_SVR = r2_score(y_train, y_train_SVR)\n",
    "print('trainig score SVR: ' + str(r2_SVR))\n",
    "\n",
    "y_test_SVR = svr_nonlin.predict(X_test)\n",
    "r2_SVR_test = r2_score(y_test, y_test_SVR)\n",
    "print('trainig score SVR: ' + str(r2_SVR_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots()\n",
    "Cstar_SAR_time.plot(ax = ax, ylabel = 'C* [mm]', label = 'PDM')\n",
    "plt.plot(X_train.index, y_train_SVR, label = 'Train', alpha = 0.7)\n",
    "plt.plot(X_test.index, y_test_SVR, label = 'Test', alpha = 0.7)\n",
    "ax.legend()\n",
    "ax.set_title('SVR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
