{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OpenEO: Sentinel 1 "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Connection to VITO backend for cloud computing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openeo\n",
    "import geopandas as gpd\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pickle\n",
    "import xarray as xr\n",
    "import hvplot.xarray\n",
    "import os\n",
    "connection = openeo.connect(\"openeo.vito.be\").authenticate_oidc()\n",
    "pad = Path(os.getcwd())\n",
    "if pad.name != \"Python\":\n",
    "    pad_correct = Path(\"../../Python\")\n",
    "    os.chdir(pad_correct)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load in the Shapefile of the Zwalm in EPSG:4326"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shape_zwalm = gpd.read_file('data/Zwalm_shape/zwalm_shapefile_emma.shp')\n",
    "shape_zwalm.plot()\n",
    "extent = shape_zwalm.total_bounds\n",
    "print(extent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extent = [3.66751526, 50.76325563, 3.83821038, 50.90341411]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#connection.list_collections()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#connection.describe_collection('SENTINEL1_GRD')\n",
    "connection.describe_collection('S1_GRD_SIGMA0_ASCENDING')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collection = 'SENTINEL1_GRD' #Ground Range Detected\n",
    "spatial_extent = {'west':extent[0],'east':extent[2],'south':extent[1],'north':extent[3]}\n",
    "temporal_extent = [\"2014-11-18\", \"2022-11-05\"]  #start with limited extent as a test\n",
    "bands = [\"VV\"] #enkel in deze ge√Ønteresseerd \n",
    "properties = {\n",
    "    \"sat:orbit_state\": lambda od: od == \"ASCENDING\", ##filter on ascending vs descending\n",
    "    \"sar:instrument_mode\":lambda mode: mode == \"IW\" ## Orbit direction filtering\n",
    "}\n",
    "s1_a = connection.load_collection(\n",
    "    collection_id = collection,\n",
    "    spatial_extent= spatial_extent,\n",
    "    temporal_extent = temporal_extent,\n",
    "    bands = bands,\n",
    "    properties = properties\n",
    ")\n",
    "s1_a = s1_a.ard_normalized_radar_backscatter(elevation_model = \"COPERNICUS_30\")\n",
    "s1_a_mask = s1_a.mask_polygon(shape_zwalm['geometry'].values[0])\n",
    "#from linear to db\n",
    "s1_a_mask = s1_a_mask.apply(lambda x:10 * x.log(base=10))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now make a job to send to the cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# job_s1a = s1_a_mask.create_job(title = \"S1-A\")\n",
    "# job_id_s1a = job_s1a.job_id\n",
    "# if job_id_s1a:\n",
    "#     print(\"Batch job created with id: \",job_id_s1a)\n",
    "#     job_s1a.start_job()\n",
    "# else:\n",
    "#     print(\"Error! Job ID is None\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# job_reconnect = connection.job(job_id_s1a)\n",
    "# job_description = job_reconnect.describe_job()\n",
    "# print(\"Batch job with id: \",job_id_s1a, ' is ',job_description['status'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attempt at splitting requests per year!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temporal_extent = [\"2014-11-18\", \"2022-11-05\"]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_temp_extent = []\n",
    "list_temp_extent.append([temporal_extent[0],\"2014-12-31\"])\n",
    "import numpy as np\n",
    "for year in np.arange(2015,2023):\n",
    "    if year == 2022:\n",
    "        #print([str(year)+\"-01-01\",temporal_extent[1]])\n",
    "        list_temp_extent.append([str(year)+\"-01-01\",temporal_extent[1]])\n",
    "    else:\n",
    "        #print([str(year)+\"-01-01\",str(year)+ \"-12-31\"])\n",
    "        list_temp_extent.append([str(year)+\"-01-01\",str(year)+ \"-12-31\"])\n",
    "print(list_temp_extent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "years = np.arange(2014,2023)\n",
    "job_title_list = []\n",
    "job_id_list = []\n",
    "for i, temporal_extent in enumerate(list_temp_extent):\n",
    "    s1_a = connection.load_collection(\n",
    "        collection_id = collection,\n",
    "        spatial_extent= spatial_extent,\n",
    "        temporal_extent = temporal_extent,\n",
    "        bands = bands,\n",
    "        properties = properties\n",
    "    )\n",
    "    s1_a = s1_a.ard_normalized_radar_backscatter(elevation_model = \"COPERNICUS_30\")\n",
    "    s1_a_mask = s1_a.mask_polygon(shape_zwalm['geometry'].values[0])\n",
    "    #from linear to db\n",
    "    #s1_a_mask = s1_a_mask.apply(lambda x:10 * x.log(base=10))\n",
    "    job_title = \"S1-A-\" +  str(years[i])\n",
    "    job_title_list.append(job_title)\n",
    "    job_s1a = s1_a_mask.create_job(title = job_title, out_format= 'NetCDF')\n",
    "    job_id_s1a = job_s1a.job_id\n",
    "    if job_id_s1a:\n",
    "        print(\"Batch job created with id: \",job_id_s1a)\n",
    "        job_s1a.start_job()\n",
    "        job_id_list.append(job_id_s1a)\n",
    "    else:\n",
    "        print(\"Error! Job ID is None\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('s1_a_job_id_list.pickle', 'wb') as handle:\n",
    "    pickle.dump(job_id_list, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_id_list = pickle.load(open(\"temp/s1_job_id_list.pickle\", \"rb\"))\n",
    "for i,job_id in enumerate(job_id_list):\n",
    "    job_connection = connection.job(job_id)\n",
    "    results = job_connection.get_results()\n",
    "    name_netcdf = job_title_list[i] + '.nc'\n",
    "    filepath = \"data/LAI/\" + name_netcdf\n",
    "    print(filepath)\n",
    "    results.download_file(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# i = 2\n",
    "# temporal_extent = list_temp_extent[i]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# s1_a = connection.load_collection(\n",
    "#         collection_id = collection,\n",
    "#         spatial_extent= spatial_extent,\n",
    "#         temporal_extent = temporal_extent,\n",
    "#         bands = bands,\n",
    "#         properties = properties\n",
    "#     )\n",
    "# s1_a = s1_a.ard_normalized_radar_backscatter(elevation_model = \"COPERNICUS_30\")\n",
    "# s1_a_mask = s1_a.mask_polygon(shape_zwalm['geometry'].values[0])\n",
    "# #from linear to db\n",
    "# s1_a_mask = s1_a_mask.apply(lambda x:10 * x.log(base=10))\n",
    "# job_title = \"S1-A-\" +  str(years[i])\n",
    "# job_title_list.append(job_title)\n",
    "# job_s1a = s1_a_mask.create_job(title = job_title, out_format='NetCDF')\n",
    "# job_id_s1a = job_s1a.job_id\n",
    "# if job_id_s1a:\n",
    "#     print(\"Batch job created with id: \",job_id_s1a)\n",
    "#     job_s1a.start_job()\n",
    "#     job_id_list.append(job_id_s1a)\n",
    "# else:\n",
    "#     print(\"Error! Job ID is None\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downloading the results test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# job_2015 = connection.job( \"j-59c6be40a6fd44cab419355802e14832\")\n",
    "# results = job_2015.get_results()\n",
    "# results.download_files(\"data/g0_OpenEO/S1_A_2015.nc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6 | packaged by conda-forge | (main, Aug 22 2022, 20:30:19) [MSC v.1929 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a6b8480143e45034b950661dc46ed3131c1d39c9fcb21ab7eff1dd297a31067d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
