{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Assimilation with Newtonian Nudging "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "pad = Path(os.getcwd())\n",
    "if pad.name == 'data_assimilation':\n",
    "    pad_correct = pad.parent\n",
    "    os.chdir(pad_correct)\n",
    "from functions.PDM import PDM\n",
    "from functions.performance_metrics import NSE, mNSE, FHV\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import matplotlib.colors as colors\n",
    "import hvplot \n",
    "import hvplot.pandas\n",
    "import itertools\n",
    "import warnings\n",
    "from numba import jit\n",
    "from datetime import datetime\n",
    "\n",
    "exec_parameter_testing = False\n",
    "presentation = False\n",
    "\n",
    "%load_ext autoreload \n",
    "%autoreload 2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run \"data_assimilation/data_prep.py\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Necessary data load in "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Needed for PDM inputs\n",
    "preprocess_output_folder = Path('data/Zwalm_data/preprocess_output')\n",
    "p_zwalm = pd.read_pickle(preprocess_output_folder / 'zwalm_p_thiessen.pkl')\n",
    "ep_zwalm = pd.read_pickle(preprocess_output_folder / 'zwalm_ep_thiessen.pkl')\n",
    "param = pd.read_csv(\"data/Zwalm_PDM_parameters/NM_opt_param.csv\")\n",
    "zwalm_shape = gpd.read_file('data/Zwalm_shape/zwalm_shapefile_emma_31370.shp')\n",
    "area_zwalm_new = np.single(zwalm_shape.area[0] / 10**6)\n",
    "deltat = np.array(1, dtype=np.float32)  # hour\n",
    "deltat_out = np.array(24, dtype=np.float32)  # daily averaging\n",
    "\n",
    "#observational C*\n",
    "ml_obs_op_pad = Path(\"data/ml_obs_op_data\")\n",
    "Cstar_obs_lin_reg = pd.read_pickle(ml_obs_op_pad/'lin_reg/full_data/y_hat_retimed.pickle')\n",
    "Cstar_obs_lin_reg_nt = pd.read_pickle(ml_obs_op_pad/'lin_reg/full_data_no_time/y_hat_retimed.pickle')\n",
    "Cstar_obs_lin_reg_nf = pd.read_pickle(ml_obs_op_pad/'lin_reg/full_data_no_forest/y_hat_retimed.pickle')\n",
    "# Cstar_obs_ridge_w = pd.read_pickle(ml_obs_op_pad/'ridge/window/y_hat_retimed.pickle')\n",
    "Cstar_obs_lasso_w = pd.read_pickle(ml_obs_op_pad/'lasso/window/y_hat_retimed.pickle')\n",
    "Cstar_obs_SVR_lin = pd.read_pickle(ml_obs_op_pad/'SVR/linear/y_hat_retimed.pickle')\n",
    "Cstar_obs_GPR = pd.read_pickle(ml_obs_op_pad/'GPR/y_hat_retimed.pickle')\n",
    "#Observational flow for comparison\n",
    "Q_obs_daily = pd.read_pickle('data/Zwalm_data/pywaterinfo_output/Q_day.pkl')\n",
    "Q_obs_daily = Q_obs_daily.rename(columns = {'Timestamp':'t'})\n",
    "Q_obs_daily = Q_obs_daily.set_index('t')\n",
    "Q_obs_daily.head(2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate model performance starting on the first day of the month of first observation. Evaluate based on daily flow!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_obs_date = Cstar_obs_lin_reg.index[0]\n",
    "start_p1 = pd.Timestamp(datetime(year = first_obs_date.year, month = first_obs_date.month, day = 1))\n",
    "print(f'Start of evaluation: {start_p1}')\n",
    "end_PDM_calibration = pd.Timestamp(datetime(year = 2019, month = 12, day = 31, hour = 23))\n",
    "begin_ML_training_only = end_PDM_calibration + np.timedelta64(1,'h')\n",
    "print(f'End of PDM calibration period: {end_PDM_calibration}')\n",
    "end_ML_training = pd.Timestamp(datetime(year = 2020, month = 12, day =31))\n",
    "print(f'End of ML training period: {end_ML_training}')\n",
    "begin_all_test = end_ML_training + np.timedelta64(1,'D')\n",
    "end_all_test = Cstar_obs_lin_reg.index[-1]\n",
    "print(f'Last date used for training {end_all_test}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define general function definition\n",
    "\n",
    "Define a function to repeatedly compare different Newtonian Nudging parameters and observation operator models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DA_OL_comparison(gamma:float, kappa:float, tau:int, Cstar_obs, plot_style = 'dynamic', return_figures = False, figs = None, axes = None,**kwargs):\n",
    "    \"\"\"\n",
    "    Wrapper for comparing OL and DA (Newtonian Nudging) version of PDM with a certain observation operator model \n",
    "\n",
    "    Parameters\n",
    "    ----------- \n",
    "    gamma: float\n",
    "        the observational uncertainty, as of now fixed for all timestamps (between 0 and 1)\n",
    "    kappa: float\n",
    "        The Nudging factor (between 0 and 1)\n",
    "    tau: int\n",
    "        The number of hours before and after the time of observation for which to apply DA.\n",
    "    Cstar_obs: pandas.Series of pandas.DataFrame\n",
    "        Dataframe/Series with the observed C* (from observation operator model) with time as idex\n",
    "    plot_style: string\n",
    "        'dynamic' execued hvplot plotting, 'static' exectued matplotlib plotting, other argument(e.g. None) disable plotting\n",
    "    return_figures: bool, default = False\n",
    "        If True, returns fig and axes object of the static plots the order they are displayed\n",
    "    figs: tuple, default = None\n",
    "        figure objects\n",
    "    axes: tuple, default = None\n",
    "        axes objects \n",
    "    **kwargs: \n",
    "        key word arguments for PDM function with DA\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    delta_dict: dictionary\n",
    "      dictionary containig the differences in NSE between DA and OL for 4 periods:\n",
    "        - Calibration: from start of observation till the end of PMD calibration\n",
    "        - ML_training: no PDM calibration, only observation operator model was trained this period\n",
    "        - Test: both PDM and observation opertor model untrained in this period\n",
    "        - Full: from start till end of observations\n",
    "        \n",
    "    figs: tuple\n",
    "        figure objects (only if return_figures = True and plot_style = 'static')\n",
    "    axes: tuple\n",
    "        axes objects (only if return_figures = True and plot_style = 'static')\n",
    "\n",
    "    \"\"\"\n",
    "    #Calculate DA and non DA PDM\n",
    "    pd_zwalm_out_DA = PDM(P=p_zwalm['P_thiessen'].values,\n",
    "                        EP=ep_zwalm['EP_thiessen'].values,\n",
    "                        t=p_zwalm['Timestamp'].values,\n",
    "                        area=area_zwalm_new, deltat=deltat, deltatout=deltat_out,\n",
    "                        parameters=param, m=3, DA = True, Cstar_obs = Cstar_obs.values.flatten(),t_obs = Cstar_obs.index.values, gamma = gamma, kappa = kappa,  tau = np.timedelta64(tau,'h'),**kwargs)\n",
    "    pd_zwalm_out_DA = pd_zwalm_out_DA.set_index('Time')\n",
    "    pd_zwalm_out = PDM(P=p_zwalm['P_thiessen'].values,\n",
    "                        EP=ep_zwalm['EP_thiessen'].values,\n",
    "                        t=p_zwalm['Timestamp'].values,\n",
    "                        area=area_zwalm_new, deltat=deltat, deltatout=deltat_out,\n",
    "                        parameters=param, m=3, DA = False)\n",
    "    pd_zwalm_out = pd_zwalm_out.set_index('Time')\n",
    "    Q_out_diff = pd_zwalm_out_DA['qmodm3s'] - pd_zwalm_out['qmodm3s'\n",
    "                                                           ]\n",
    "    #Plotting\n",
    "    diff_Cstar = pd_zwalm_out_DA['Cstar'] - pd_zwalm_out['Cstar']\n",
    "    if plot_style == 'dynamic':\n",
    "        display(pd_zwalm_out_DA['Cstar'][start_p1:].hvplot(ylabel='[mm]',\n",
    "            label = 'C* DA')*pd_zwalm_out['Cstar'][start_p1:].hvplot(label = 'C* OL'))\n",
    "        display(diff_Cstar[start_p1:].hvplot(ylabel='[mm]', label = r'$\\Delta C^* $'))\n",
    "\n",
    "        display(Q_obs_daily['Value'][start_p1:].hvplot(label = 'Observed')*pd_zwalm_out_DA['qmodm3s'][start_p1:].hvplot(ylabel='[m^3/s]',label = 'DA')*pd_zwalm_out['qmodm3s'][start_p1:].hvplot(label = 'OL',line_dash = 'dotted', frame_width = 800, frame_height = 400))\n",
    "\n",
    "        display(Q_out_diff[start_p1:].hvplot(title = 'Q_out DA - Q_out OL', ylabel = '[m^3/s]', frame_width = 800))\n",
    "    \n",
    "    elif plot_style == 'static':\n",
    "        if (figs == None) and (axes == None):\n",
    "            figs_list = []\n",
    "            axes_list = []\n",
    "            for i in range(4):\n",
    "                fig_temp, ax_temp = plt.subplots()\n",
    "                figs_list.append(fig_temp)\n",
    "                axes_list.append(ax_temp)\n",
    "            figs = tuple(figs_list)\n",
    "            axes = tuple(axes_list)\n",
    "        pd_zwalm_out_DA['Cstar'][start_p1:].plot(label = 'DA', ylabel = r'$C^*$ [mm]', ax = axes[0], c = 'tab:orange')#type:ignore\n",
    "        pd_zwalm_out['Cstar'][start_p1:].plot(label = 'OL', ax = axes[0], c = 'tab:green')#type:ignore\n",
    "        axes[0].legend()#type:ignore\n",
    "\n",
    "        diff_Cstar[start_p1:].plot(ylabel=r'$C^*_{\\rm DA} - C^*_{\\rm OL}$ [mm]', ax = axes[1])#type:ignore\n",
    "        Q_obs_daily['Value'][start_p1:].plot(label = 'Observed', ax = axes[2])\n",
    "        pd_zwalm_out_DA['qmodm3s'][start_p1:].plot(ylabel= r'$Q$ [m$^3$/s]', label = 'DA', ax = axes[2])#type:ignore\n",
    "        pd_zwalm_out['qmodm3s'][start_p1:].plot(label = 'OL',linestyle = 'dotted', ax = axes[2])#type:ignore\n",
    "        axes[2].legend()#type:ignore\n",
    "\n",
    "        Q_out_diff[start_p1:].plot(ylabel = r'$Q_{\\rm DA} - Q_{\\rm OL}$  [m$^3$/s]', ax = axes[3])#type:ignore\n",
    "\n",
    "    #Metrics\n",
    "    def metric_wrapper_DA_OL_comparison(function, metric_name, p_start,p_end):\n",
    "        metric_OL = function(pd_zwalm_out['qmodm3s'][p_start:p_end],Q_obs_daily['Value'][p_start:p_end])\n",
    "        metric_DA = function(pd_zwalm_out_DA['qmodm3s'][p_start:p_end],Q_obs_daily['Value'][p_start:p_end])\n",
    "        print(f'OL {metric_name} from {p_start} till {p_end}: {metric_OL}')\n",
    "        print(f'DA {metric_name} from {p_start} till {p_end}: {metric_DA}')\n",
    "        if metric_name == 'FHV':\n",
    "            delta_metric = np.abs(metric_DA) - np.abs(metric_OL)\n",
    "        else:\n",
    "            delta_metric = metric_DA - metric_OL\n",
    "        print(f'Delta {metric_name}: {delta_metric}')\n",
    "        return metric_OL, metric_DA, delta_metric\n",
    "    metric_dict = {'NSE':NSE, 'mNSE':mNSE, 'FHV':FHV}\n",
    "    delta_dict = {}\n",
    "    for metric_name in metric_dict.keys():   \n",
    "        print('\\n ------------------')\n",
    "        print(f'METRIC: {metric_name}')\n",
    "        print('---------------------')\n",
    "        metric_OL_cal, metric_DA_cal, delta_cal = metric_wrapper_DA_OL_comparison(metric_dict[metric_name],metric_name,start_p1,end_PDM_calibration)\n",
    "        print('\\n')\n",
    "        metric_OL_MLt, metric_DA_MLt, delta_MLt =  metric_wrapper_DA_OL_comparison(metric_dict[metric_name],metric_name,begin_ML_training_only,end_ML_training)\n",
    "        print('\\n')\n",
    "        metric_OL_test, metric_DA_test, delta_test = metric_wrapper_DA_OL_comparison(metric_dict[metric_name],metric_name,begin_all_test,end_all_test)\n",
    "        print('\\n')\n",
    "        metric_OL_full, metric_DA_full, delta_full = metric_wrapper_DA_OL_comparison(metric_dict[metric_name],metric_name,start_p1,end_all_test)\n",
    "        # metric_dict = {'OL_cal':metric_OL_cal, 'DA_cal':metric_DA_cal,'OL_ML_training':metric_OL_MLt, 'DA_ML_training':metric_DA_MLt, 'metric_OL_test':metric_OL_test, 'metric_DA_test':metric_DA_test,'metric_OL_full':metric_OL_full, 'metric_DA_full':metric_DA_full}\n",
    "        delta_dict_temp = {'delta_cal':delta_cal, 'delta_Mlt':delta_MLt,'delta_test':delta_test, 'delta_full':delta_full}\n",
    "        delta_dict[metric_name] = delta_dict_temp\n",
    "    if not return_figures:\n",
    "        return delta_dict\n",
    "    else:\n",
    "        if plot_style == 'static':\n",
    "            return delta_dict, figs, axes\n",
    "        else:\n",
    "            raise ValueError(\"Plot style must be 'static' to allow 'return figures' to be true\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start with $\\tau = 5h$ day, $K*\\gamma$ = 0.5"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear regressinon: full feature set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kappa = 1\n",
    "gamma = 0.25#0.5\n",
    "tau = 2#5\n",
    "font_size = 13\n",
    "if presentation:\n",
    "    plt.rcParams.update({'font.size': font_size})\n",
    "delta_dict, figs, axes = DA_OL_comparison(gamma, kappa, tau, Cstar_obs_lin_reg, plot_style = 'static', return_figures=True)\n",
    "#combined_figure=True)\n",
    "display(delta_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pad_pres = Path('Figures/presentation_12_04')\n",
    "if not os.path.exists(pad_pres):\n",
    "    os.makedirs(pad_pres)\n",
    "if presentation:\n",
    "    if len(figs) == 4: \n",
    "        fig_diff = figs[2]\n",
    "        ax_diff = axes[2]\n",
    "        ax_diff.set_xlabel('Tijd')\n",
    "        ax_diff.set_title(r'Lineare regressie: $Q_{out}$ DA - $Q_{out}$ OL')\n",
    "        fig_diff.savefig(pad_pres/'Q_diff_lin_reg.svg',format = 'svg')\n",
    "        display(fig_diff)\n",
    "    else:\n",
    "        fig_combined = figs[1]\n",
    "        fig_combined.suptitle('Linear regression')\n",
    "        display(fig_combined)\n",
    "        fig_combined.savefig(pad_pres/'Q_DA_vs_OL_lin_reg.svg',format = 'svg', transparent = True)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear regression: no time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig1, (ax1, ax2) = plt.subplots(2,1, figsize = (6,7), constrained_layout = True)\n",
    "fig2, (ax3,ax4) = plt.subplots(2,1, figsize = (6,7), constrained_layout = True)\n",
    "figs = (fig1, fig2)\n",
    "axes = (ax1, ax2, ax3, ax4)\n",
    "\n",
    "DA_OL_comparison(gamma, kappa, tau, Cstar_obs_lin_reg_nt, plot_style = 'static', figs = figs, axes = axes)\n",
    "\n",
    "axes[0].set_xlabel('')\n",
    "axes[2].set_xlabel('')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear regression: no forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig1, ((ax1_nf, ax1_gpr),(ax2_nf, ax2_gpr) ) = plt.subplots(2,2, figsize = (9,6), constrained_layout = True)#, sharey = 'row')\n",
    "# fig2, ((ax3_nf, ax3_gpr),(ax4_nf, ax4_gpr) ) = plt.subplots(2,2, figsize = (9,6), constrained_layout = True)#, sharey = 'row')\n",
    "# figs = (fig1, fig2)\n",
    "# axes = (ax1_nf, ax2_nf, ax3_nf, ax4_nf)\n",
    "\n",
    "delta_dict = DA_OL_comparison(gamma, kappa, tau, Cstar_obs_lin_reg_nf, plot_style = 'dynamic')\n",
    "display(delta_dict)\n",
    "# #C* plot\n",
    "# axes[0].set_xlabel('')\n",
    "# axes[0].set_title('(a)')\n",
    "# # Cstar_plot_nf = Cstar_obs_lin_reg_nf.reset_index()\n",
    "# # Cstar_plot_nf.plot.scatter(x = 't', y = 'C*', ax = axes[0], marker = \"x\")\n",
    "# ylim_C_diff = axes[1].get_ylim()\n",
    "# #Q plot\n",
    "# axes[2].set_xlabel('')\n",
    "# axes[2].set_title('(a)')\n",
    "# ylim_Q_diff = axes[3].get_ylim()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lasso window regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DA_OL_comparison(gamma, kappa, tau, Cstar_obs_ridge_w['C*'], plot_style = 'dynamic')\n",
    "dict_out = DA_OL_comparison(gamma, kappa, tau, Cstar_obs_lasso_w['C*'], plot_style = 'dynamic')\n",
    "display(dict_out)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_dict = DA_OL_comparison(gamma, kappa, tau, Cstar_obs_SVR_lin['C*'], plot_style = 'dynamic')\n",
    "display(out_dict)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GPR"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "rerun LR for visulisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig1, ((ax1_nf, ax1_gpr),(ax2_nf, ax2_gpr) ) = plt.subplots(2,2, figsize = (9,6), constrained_layout = True)#, sharey = 'row')\n",
    "fig2, ((ax3_nf, ax3_gpr),(ax4_nf, ax4_gpr) ) = plt.subplots(2,2, figsize = (9,6), constrained_layout = True)#, sharey = 'row')\n",
    "figs = (fig1, fig2)\n",
    "axes = (ax1_nf, ax2_nf, ax3_nf, ax4_nf)\n",
    "\n",
    "delta_dict, figs, axes = DA_OL_comparison(gamma, kappa, tau, Cstar_obs_lin_reg, plot_style = 'static', return_figures= True, figs = figs, axes = axes)\n",
    "display(delta_dict)\n",
    "#C* plot\n",
    "axes[0].set_xlabel('')\n",
    "axes[0].set_title('(a)')\n",
    "# Cstar_plot_nf = Cstar_obs_lin_reg_nf.reset_index()\n",
    "# Cstar_plot_nf.plot.scatter(x = 't', y = 'C*', ax = axes[0], marker = \"x\")\n",
    "ylim_C_diff = axes[1].get_ylim()\n",
    "#Q plot\n",
    "axes[2].set_xlabel('')\n",
    "axes[2].set_title('(a)')\n",
    "ylim_Q_diff = axes[3].get_ylim()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GPR itself"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if presentation:\n",
    "    figs = None\n",
    "    axes = None\n",
    "else:\n",
    "    figs = (fig1, fig2)\n",
    "    axes = (ax1_gpr, ax2_gpr, ax3_gpr, ax4_gpr)\n",
    "delta_dict, figs, axes = DA_OL_comparison(gamma, kappa, tau, Cstar_obs_GPR['C*'], plot_style = 'static', return_figures=True, figs = figs, axes = axes)\n",
    "display(delta_dict)\n",
    "pad_figures_text = Path('Figures/Figures_chapter_DA')\n",
    "if not os.path.exists(pad_figures_text):\n",
    "    os.makedirs(pad_figures_text)\n",
    "if not presentation:\n",
    "    #C* plot\n",
    "    axes[0].set_xlabel('')\n",
    "    axes[0].set_ylabel('')\n",
    "    axes[1].set_ylabel('')\n",
    "    axes[0].set_title('(b)')\n",
    "    axes[1].set_ylim(ylim_C_diff)\n",
    "    display(figs[0])\n",
    "    figs[0].savefig(\n",
    "        pad_figures_text/'Cstar_lr_gpr_comparison.pdf',format = 'pdf', bbox_inches = 'tight'\n",
    "    )\n",
    "    #Q plot\n",
    "    axes[2].set_xlabel('')\n",
    "    axes[2].set_ylabel('')\n",
    "    axes[3].set_ylabel('')\n",
    "    axes[2].set_title('(b)')\n",
    "    axes[3].set_ylim(ylim_Q_diff)\n",
    "    display(figs[1])\n",
    "    figs[1].savefig(\n",
    "        pad_figures_text/'Q_lr_gpr_comparison.pdf', format = 'pdf', bbox_inches = 'tight'\n",
    "    )\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if presentation:\n",
    "    if len(figs) == 4: #for if combined figures is F\n",
    "        fig_diff = figs[2]\n",
    "        ax_diff = axes[2]\n",
    "        ax_diff.set_xlabel('Tijd')\n",
    "        ax_diff.set_title(r'Gaussiaanse Processen: $Q_{out}$ DA - $Q_{out}$ OL')\n",
    "        fig_diff.savefig(pad_pres/'Q_diff_gpr.svg',format = 'svg')\n",
    "        display(fig_diff)\n",
    "    else:\n",
    "        fig_combined = figs[1]\n",
    "        fig_combined.suptitle('Gaussian processes')\n",
    "        display(fig_combined)\n",
    "        fig_combined.savefig(pad_pres/'Q_DA_vs_OL_gpr.svg',format = 'svg', transparent = True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparison of different Newtonian Nudging parameters"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Possible parameter combinations:\n",
    "- $\\tau$: 5hours, 0.5, 1 or 1.5 days (not more, since at times 3 days between observations => for more than 1.5 days, code should change to include multiple observations)\n",
    "- $\\gamma K$: 0.1, 0.25, 0.5, 0.75, for which higher means a higher strenght of assimilation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd_Cstar = Cstar_obs_lin_reg.join(\n",
    "#     [Cstar_obs_lin_reg_nt, Cstar_obs_ridge_w, Cstar_obs_SVR_lin, Cstar_obs_GPR], rsuffix = ['_lin_reg_nt','_ridge_w','_SVR_lin','_GPR']\n",
    "# )\n",
    "\n",
    "pd_Cstar = Cstar_obs_lin_reg.join(Cstar_obs_lin_reg_nf['C*'], rsuffix='_lin_reg_nf')\n",
    "#pd_Cstar = pd_Cstar.join(Cstar_obs_ridge_w['C*'], rsuffix='_ridge_w')\n",
    "pd_Cstar = pd_Cstar.join(Cstar_obs_lasso_w['C*'], rsuffix = '_lasso_w')\n",
    "pd_Cstar = pd_Cstar.join(Cstar_obs_SVR_lin, rsuffix='_SVR_lin')\n",
    "pd_Cstar = pd_Cstar.join(Cstar_obs_GPR, rsuffix='_GPR')\n",
    "pd_Cstar = pd_Cstar.rename(columns = {'C*':'C*_lin_reg'})\n",
    "display(pd_Cstar)\n",
    "\n",
    "pad = Path('data/data_assimilation')\n",
    "if not os.path.exists(pad):\n",
    "    os.makedirs(pad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "taus = [1,2,5,int(0.5*24), int(1*24),int(1.5*24)]\n",
    "gammas = [0.1,0.25,0.5,0.75]\n",
    "ml_obs_op_models = ['lin_reg','lin_reg_nf','lasso_w','SVR_lin','GPR']\n",
    "combos = itertools.product(ml_obs_op_models,gammas,taus)\n",
    "nr_combiations = len(taus)*len(gammas)*len(ml_obs_op_models)\n",
    "kappa = 1\n",
    "if exec_parameter_testing:\n",
    "    for i, combo in enumerate(combos):\n",
    "        model_name, gamma, tau = combo\n",
    "        print(f'Combintaion {i} out of {nr_combiations}: tau = {combo[2]} hours, gamma ={combo[1]} and {combo[0]} as observation operator')\n",
    "        Cstar_temp = pd_Cstar.iloc[:,pd_Cstar.columns.str.endswith(model_name)]\n",
    "        Cstar_temp = Cstar_temp.dropna() #to deal with window mehtods\n",
    "        delta_dict = DA_OL_comparison(kappa, float(gamma), int(tau), Cstar_temp, plot_style = None)\n",
    "        delta_NSE_dict = delta_dict['NSE']\n",
    "        if i == 0:\n",
    "            pd_comparison = pd.DataFrame(delta_NSE_dict, index = pd.MultiIndex.from_tuples([combo], names = ['obs_op_model','gamma','tau']))\n",
    "        else:\n",
    "            pd_temp = pd.DataFrame(delta_NSE_dict, index = pd.MultiIndex.from_tuples([combo], names = ['obs_op_model','gamma','tau']))\n",
    "            pd_comparison = pd.concat([pd_comparison, pd_temp])\n",
    "    pd_comparison.to_pickle(pad/'pd_comparison.pkl')\n",
    "else:\n",
    "    pd_comparison = pd.read_pickle(pad/'pd_comparison.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_improv = np.max(pd_comparison.max())\n",
    "max_deteriation = np.min(pd_comparison.min())\n",
    "if max_improv < 0:\n",
    "    warnings.warn('No improvement made!')\n",
    "limit = np.max([max_improv, np.abs(max_deteriation)])\n",
    "\n",
    "print(np.max(pd_comparison.max()))\n",
    "print(np.min(pd_comparison.min()))\n",
    "pd_comparison.style.background_gradient(cmap = 'coolwarm', vmin =-limit, vmax = limit)#'RdYlGn_r'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_comparison_sort_cal = pd_comparison.sort_values('delta_cal',ascending = False)\n",
    "pd_comparison_sort_cal.style.background_gradient(cmap = 'coolwarm', vmin =-limit, vmax = limit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_comparison_sort_test = pd_comparison.sort_values('delta_test',ascending = False)\n",
    "pd_comparison_sort_test.style.background_gradient(cmap = 'coolwarm', vmin =-limit, vmax = limit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "periods_score_correlaiton = pd_comparison.corr()\n",
    "periods_score_correlaiton.style.background_gradient(cmap = 'coolwarm', vmin =- 1, vmax = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_comparison_sort_full = pd_comparison.sort_values('delta_full',ascending = False)\n",
    "pd_comparison_sort_full.style.background_gradient(cmap = 'coolwarm', vmin =-limit, vmax = limit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_comparison.plot.kde()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_comparison.groupby('obs_op_model').plot.kde(legend = True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make scaterplots of model performance based on $\\Kappa \\gamma$ and $\\tau$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# columns_periods = pd_comparison.columns\n",
    "# column_names = ['P1','P2','P3','PFull']\n",
    "# model_names = ['LR full','LR full no forest',r'LaR full $\\tau = 30$', r'Linear $\\epsilon-$SVR full', 'GPR full']\n",
    "# unique_models = pd_comparison.index.get_level_values('obs_op_model').unique()\n",
    "\n",
    "# fig, axes = plt.subplots(len(unique_models),len(columns_periods), figsize = (12,12), constrained_layout = True)\n",
    "# for i,model in enumerate(unique_models):\n",
    "#     for j,period in enumerate(columns_periods):\n",
    "#         print(str(period) + ', ' + model)\n",
    "#         pd_temp = pd_comparison.loc[(model,), period]\n",
    "#         pd_temp_unstacked = pd_temp.unstack()\n",
    "#         xv, yv = np.meshgrid(pd_temp_unstacked.index.values, \n",
    "#                              pd_temp_unstacked.columns.values)\n",
    "#         map = axes[i,j].scatter(xv, yv, c = pd_temp_unstacked.values.T,\n",
    "#                                 norm = colors.SymLogNorm(vmin = -limit, vmax = limit, linthresh = 1e-4), cmap = 'coolwarm')#, vmin = -limit, vmax = limit, cmap = 'coolwarm'\n",
    "#         if i == 0:\n",
    "#             axes[i,j].set_title(column_names[j])\n",
    "#             # axes[i,j].set_ylabel(r'$\\tau$ [h]')\n",
    "\n",
    "#         if i == len(unique_models) - 1: \n",
    "#             axes[i,j].set_xlabel(r'$\\gamma$ [-]')\n",
    "#         if j == len(columns_periods) - 1:\n",
    "#             plt.colorbar(map, ax = axes[i,j])          \n",
    "#     plt.setp(axes[i,0], ylabel = model_names[i])\n",
    "# #plt.setp(axes[:, 0], ylabel='y axis label')\n",
    "# fig.supylabel(r'$\\Delta \\rm NSE$', x = 1)\n",
    "# # fig.savefig(pad_figures_text/'DA_parameters_test.pdf', format = 'pdf', bbox_inches = 'tight')\n",
    "#fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_periods = pd_comparison.columns\n",
    "print(columns_periods)\n",
    "column_names = ['P1','P2','P3','PFull']\n",
    "model_names = ['LR full','LR full no forest',r'LaR full $\\tau = 30$', r'Linear $\\epsilon-$SVR full', 'GPR full']\n",
    "unique_models = pd_comparison.index.get_level_values('obs_op_model').unique()\n",
    "\n",
    "fig = plt.figure(constrained_layout = True, figsize = (9,9))\n",
    "\n",
    "subfigs = fig.subfigures(nrows = len(unique_models), ncols = 1)\n",
    "for row, subfig in enumerate(subfigs):\n",
    "    subfig.suptitle(model_names[row])\n",
    "    axes = subfig.subplots(nrows = 1, ncols = 4)\n",
    "    for col, ax in enumerate(axes):\n",
    "        pd_temp = pd_comparison.loc[(unique_models[row],), columns_periods[col]]\n",
    "        pd_temp_unstacked = pd_temp.unstack()\n",
    "        xv, yv = np.meshgrid(pd_temp_unstacked.index.values, \n",
    "                        pd_temp_unstacked.columns.values)\n",
    "        map = ax.scatter(xv, yv, c = pd_temp_unstacked.values.T,\n",
    "                                norm = colors.SymLogNorm(vmin = -limit, vmax = limit, linthresh = 1e-4), cmap = 'coolwarm')\n",
    "        if row == len(model_names) - 1:\n",
    "            ax.set_xlabel(r'$\\gamma$ [-]')\n",
    "        if col == 0:\n",
    "            ax.set_ylabel(r'$\\tau$ [h]')\n",
    "    plt.colorbar(map, ax = ax) \n",
    "fig.supylabel(r'$\\Delta \\rm NSE$', x = 1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternative visualisation below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(constrained_layout = True, figsize = (9,9))\n",
    "\n",
    "subfigs = fig.subfigures(nrows = len(unique_models), ncols = 1)\n",
    "for row, subfig in enumerate(subfigs):\n",
    "    subfig.suptitle(model_names[row])\n",
    "    axes = subfig.subplots(nrows = 1, ncols = 4)\n",
    "    for col, ax in enumerate(axes):\n",
    "        pd_temp = pd_comparison.loc[(unique_models[row],), columns_periods[col]]\n",
    "        pd_temp_unstacked = pd_temp.unstack()\n",
    "        map = ax.imshow(pd_temp_unstacked.values.T,norm = colors.SymLogNorm(vmin = -limit, vmax = limit, linthresh = 1e-2, linscale = 0.3), cmap = 'coolwarm',aspect = 'auto')\n",
    "        ax.set_xticks(np.arange(pd_temp_unstacked.values.shape[0]))\n",
    "        ax.set_xticklabels(gammas)\n",
    "        ax.set_yticks(np.arange(pd_temp_unstacked.values.shape[1]))\n",
    "        ax.set_yticklabels(taus)\n",
    "        if row == 0:\n",
    "            ax.set_title(column_names[col])\n",
    "        if row == len(model_names) - 1:\n",
    "            ax.set_xlabel(r'$\\gamma$ [-]')\n",
    "        if col == 0:\n",
    "            ax.set_ylabel(r'$\\tau_a$ [h]')\n",
    "    plt.colorbar(map, ax = ax) \n",
    "fig.supylabel(r'$\\Delta \\rm NSE$', x = 1)\n",
    "fig.savefig(pad_figures_text/'DA_parameters_test.pdf', format = 'pdf', bbox_inches = 'tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "limit_test = np.max(np.abs(pd_temp_unstacked.values))\n",
    "pd_temp_unstacked.T.style.background_gradient(cmap='coolwarm', vmin = -limit_test, vmax = limit_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unstacked_df = pd_temp.unstack()\n",
    "# display(unstacked_df)\n",
    "# xv, yv = np.meshgrid(unstacked_df.index.values, unstacked_df.columns.values)\n",
    "# plt.scatter(xv, yv, c = unstacked_df.values.T, s= 100)\n",
    "# plt.colorbar()\n",
    "# plt.title('')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualisation of time weighing function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tau_weighing(delta_t_abs, tau):\n",
    "    if delta_t_abs < tau/2:\n",
    "        W_t = 1\n",
    "    elif delta_t_abs < tau:\n",
    "        W_t = (tau - delta_t_abs)/(tau/2)\n",
    "    else:\n",
    "        W_t = 0\n",
    "    return W_t\n",
    "weights = [tau_weighing(np.abs(delta_t), 12) for delta_t in np.arange(-20,20,1)]\n",
    "font_size = 13\n",
    "if presentation:\n",
    "    plt.rcParams.update({'font.size': font_size})\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(np.arange(-20,20), weights)\n",
    "ax.set_ylabel('$W_t$')\n",
    "ax.set_xlabel('$t - t^*$ [u]')\n",
    "pad_pres = Path('Figures/presentation_12_04')\n",
    "if not os.path.exists(pad_pres):\n",
    "    os.makedirs(pad_pres)\n",
    "if presentation:\n",
    "    fig.savefig(pad_pres/'W_t.svg',format = 'svg')\n",
    "    plt.rcParams.update(matplotlib.rcParamsDefault)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extra experiment: improvement if mistake in forcing data aka missing rain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_zwalm_t = p_zwalm.rename(columns= {'Timestamp':'t'})\n",
    "p_zwalm_t = p_zwalm_t.set_index('t')\n",
    "#resample to daily rai\n",
    "p_zwalm_t_daily = p_zwalm_t.resample('1D').sum()\n",
    "p_zwalm_t_daily['P_thiessen'].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "day_Cstar_obs = Cstar_obs_lin_reg.index.strftime('%Y-%m-%d') #only keep day information\n",
    "#now select days in the test period\n",
    "day_Cstar_obs_test = day_Cstar_obs[day_Cstar_obs > begin_all_test.strftime('%Y-%m-%d')]\n",
    "print(day_Cstar_obs_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now select rain days with observation in test period"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0: Wrong direction\n",
    "1: bad performance even with good forcings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_test_observation = p_zwalm_t_daily.loc[day_Cstar_obs_test]\n",
    "p_test_observation_sorted = p_test_observation.sort_values('P_thiessen', ascending = False)\n",
    "display(p_test_observation_sorted.head(10))\n",
    "day_max_rain = p_test_observation_sorted.index[2]\n",
    "print(day_max_rain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "day_max_rain.date()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now make an adjusted rain dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bool_dates = []\n",
    "for i in range(len(p_zwalm_t.index)):\n",
    "    bool_dates.append(p_zwalm_t.index[i].date() == day_max_rain.date()) #dus zelfde dag\n",
    "p_zwalm_t_adapted = p_zwalm_t.copy()\n",
    "p_zwalm_t_adapted.loc[bool_dates,'P_thiessen'] = 0.2*p_zwalm_t.loc[bool_dates,'P_thiessen'].values\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define days to inspect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "begin_inspect = day_max_rain - pd.DateOffset(days = 1)\n",
    "end_inspect = day_max_rain + pd.DateOffset(days =4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd_max_rain = p_zwalm_t[bool_dates]\n",
    "p_zwalm_event_window = p_zwalm_t.loc[begin_inspect:end_inspect]\n",
    "p_zwalm_adapted_event_window = p_zwalm_t_adapted.loc[begin_inspect:end_inspect]\n",
    "fig, ax = plt.subplots()\n",
    "p_zwalm_event_window['P_thiessen'].plot(ax = ax, label = 'Original')\n",
    "p_zwalm_adapted_event_window['P_thiessen'].plot(ax=ax, label = 'Adapted')\n",
    "ax.set_ylabel('$P$ [mm/h]')\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q_obs_event_window = Q_obs_daily.loc[begin_inspect:end_inspect]\n",
    "fig, ax = plt.subplots()\n",
    "Q_obs_event_window['Value'].plot(ax = ax)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First check how the model performs in normal conditions: use the linear regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma = 0.5\n",
    "tau = 5\n",
    "delta_dict, figs, axes = DA_OL_comparison(gamma, kappa, tau, Cstar_obs_lin_reg_nf, plot_style = 'static', return_figures= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "axes[2].set_xlim(begin_inspect, end_inspect)\n",
    "axes[2].set_ylim(0,8)\n",
    "axes[2].set_title('pefect forcings')\n",
    "figs[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deltat_out = 24\n",
    "arguments_PDM = {'P':p_zwalm['P_thiessen'].values,'EP':ep_zwalm['EP_thiessen'].values, 't':p_zwalm_t.index.values,'area':area_zwalm_new, 'deltat':deltat,'deltatout':deltat_out,'parameters':param}\n",
    "arguments_PDM_adapted = arguments_PDM.copy()\n",
    "arguments_PDM_adapted['P'] = p_zwalm_t_adapted['P_thiessen'].values\n",
    "\n",
    "#For DA\n",
    "arguments_PDM_DA = arguments_PDM.copy()\n",
    "arguments_PDM_DA['DA'] = True\n",
    "arguments_PDM_DA['t_obs'] = Cstar_obs_lin_reg.index.values\n",
    "arguments_PDM_DA['Cstar_obs']  = Cstar_obs_lin_reg_nf.values\n",
    "arguments_PDM_DA['kappa'] = kappa\n",
    "arguments_PDM_DA['gamma'] = gamma\n",
    "arguments_PDM_DA['tau'] = np.timedelta64(tau,'h')\n",
    "arguments_PDM_DA_adapted = arguments_PDM_DA.copy()\n",
    "arguments_PDM_DA_adapted['P'] = p_zwalm_t_adapted['P_thiessen'].values\n",
    "all(arguments_PDM_DA_adapted['P'] == arguments_PDM_DA['P'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdm_out_normal = PDM(**arguments_PDM)\n",
    "pdm_out_normal_DA = PDM(**arguments_PDM_DA)\n",
    "\n",
    "pdm_out_adapted = PDM(**arguments_PDM_adapted)\n",
    "pdm_out_adapted_DA = PDM(**arguments_PDM_DA_adapted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdm_out_normal = pdm_out_normal.set_index('Time')\n",
    "pdm_out_normal_DA = pdm_out_normal_DA.set_index('Time')\n",
    "pdm_out_adapted_DA = pdm_out_adapted_DA.set_index('Time')\n",
    "pdm_out_adapted = pdm_out_adapted.set_index('Time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "Q_obs_daily['Value'].plot(ax =ax ,label = 'Observed')\n",
    "pdm_out_normal_DA['qmodm3s'].plot(ax = ax, label = 'DA')\n",
    "pdm_out_normal['qmodm3s'].plot(ax = ax, label = 'OL')\n",
    "pdm_out_adapted_DA['qmodm3s'].plot(ax = ax, label = 'DA adapted')\n",
    "pdm_out_adapted['qmodm3s'].plot(ax = ax, label = 'OL adapted')\n",
    "ax.set_xlim(begin_inspect, end_inspect)\n",
    "ax.set_ylim(0,2)\n",
    "ax.set_ylabel('$Q$ [m$^3$/s]')\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "Cstar_plot = Cstar_obs_lin_reg_nf.reset_index()\n",
    "Cstar_plot.plot.scatter(x = 't', y = 'C*', ax=ax, label = 'Retrieval')\n",
    "pdm_out_normal_DA['Cstar'].plot(ax=ax,label = 'DA', color = 'tab:orange')\n",
    "pdm_out_normal['Cstar'].plot(ax = ax, label = 'OL', color = 'tab:green')\n",
    "pdm_out_adapted_DA['Cstar'].plot(ax=ax,label = 'DA adapted', color = 'tab:red')\n",
    "pdm_out_adapted['Cstar'].plot(ax = ax, label = 'OL adapted', color = 'tab:purple')\n",
    "fig\n",
    "ax.legend()\n",
    "ax.set_xlim(begin_inspect, end_inspect)\n",
    "ax.set_ylim(200,300)\n",
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all(pdm_out_adapted['qmodm3s'] == pdm_out_adapted_DA['qmodm3s'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A Very simple experiment with S1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Update 31/05/2023: with the change where I update $S_1$ in function of the a posteriori $C*$, this idea is not longer useful"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thesis: GPR and linear regression on full dataset to be discussed! => I can make analogous figures to the ones used previously!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pdm_out_normal = PDM(**arguments_PDM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pdm_out_normal_t = pdm_out_normal.set_index('Time')\n",
    "# S1 = pdm_out_normal_t['S1']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load in extra modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from functions.ml_utils import general_sklearn_model\n",
    "# from sklearn.linear_model import LinearRegression, LassoCV\n",
    "# from sklearn.model_selection import GridSearchCV\n",
    "# from sklearn.svm import SVR\n",
    "# from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "# from sklearn.gaussian_process.kernels import RBF, WhiteKernel\n",
    "# from sklearn.pipeline import make_pipeline\n",
    "# from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in extra data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ML_data_pad = Path(\"data/Zwalm_data/ML_data\")\n",
    "# X_train = pd.read_pickle(ML_data_pad/\"X_train.pkl\")\n",
    "# X_test = pd.read_pickle(ML_data_pad/\"X_test.pkl\")\n",
    "# S1_train = S1.loc[X_train.index]\n",
    "# S1_test = S1.loc[X_test.index]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # X_train_no_forest = X_train#.loc[:,~X_train.columns.str.endswith('Forest')]\n",
    "# # X_test_no_forest = X_test#.loc[:,~X_test.columns.str.endswith('Forest')]\n",
    "# linreg_drop_forest, r2_train, r2_test, fig, ax, S1_train_obs, S1_test_obs = general_sklearn_model(\n",
    "#     LinearRegression(), X_train, X_test,\n",
    "#     S1_train.values.reshape(-1,1), S1_test.values.reshape(-1,1),\n",
    "#     X_train.index, X_test.index, S1, normalisation = True, return_predictions = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# S1_obs = pd.concat([S1_train_obs,S1_test_obs])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zie S1_test.txt: gamma = 0.25 and tau = 2 works well!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig1, ((ax1_lr, ax1_gpr),(ax2_lr, ax2_gpr) ) = plt.subplots(2,2, figsize = (9,6), constrained_layout = True)#, sharey = 'row')\n",
    "# fig2, ((ax3_lr, ax3_gpr),(ax4_lr, ax4_gpr) ) = plt.subplots(2,2, figsize = (9,6), constrained_layout = True)#, sharey = 'row')\n",
    "# figs = (fig1, fig2)\n",
    "# axes = (ax1_lr, ax2_lr, ax3_lr, ax4_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tau = 2\n",
    "# kappa = 1\n",
    "# gamma = 0.25\n",
    "# delta_dict, figs, axes = DA_OL_comparison(gamma, kappa, tau, S1_obs, plot_style = 'static', DA_experiment= True, return_figures = True, figs = figs, axes = axes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #S1 plot\n",
    "# axes[0].set_ylabel('$S_1$ [mm]')\n",
    "# axes[0].set_xlabel('')\n",
    "# axes[0].set_title('(a)')\n",
    "# axes[1].set_ylabel(r'$S_{1, \\rm DA} - S_{1,\\rm OL}$ [mm]')\n",
    "# ylim_S1_df = axes[1].get_ylim()\n",
    "# display(figs[0])\n",
    "\n",
    "# #Q plot\n",
    "# axes[2].set_xlabel('')\n",
    "# axes[2].set_title('(a)')\n",
    "# ylim_Q_lr = axes[3].get_ylim()\n",
    "\n",
    "# display(figs[1])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVR RBF "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # svr_rbf_eps = SVR(kernel = 'rbf', epsilon = 0.1)\n",
    "# # svr_gs_rbf_eps = GridSearchCV(svr_rbf_eps, param_grid = {\n",
    "# #     'C':np.logspace(-10,3,14),\n",
    "# #     'gamma':np.logspace(-5,5,50)\n",
    "# # }, scoring = 'r2', cv = 5, n_jobs = -1, verbose = 3\n",
    "# # )\n",
    "# svr_rbf = SVR(kernel = 'rbf', C = 1, epsilon = 0.1, gamma ='auto') \n",
    "# # if exec_hyperopt_tuning: \n",
    "# SVR_out, r2_train, r2_test, fig, ax, S1_train_SVR, S1_test_SVR = general_sklearn_model(\n",
    "#     svr_rbf, X_train, X_test, S1_train.values.reshape(-1,1), S1_test.values.reshape(-1,1),X_train.index, X_test.index,S1, normalisation = True, return_predictions = True\n",
    "#     )\n",
    "#     # svr_gs_tuple_out = general_sklearn_model(\n",
    "#     #     svr_gs_rbf_rains, X_train_small.drop(['VH_past_agr'], axis = 1), X_test_small.drop(['VH_past_agr'], axis = 1), y_train.values.reshape(-1,1), y_test.values.reshape(-1,1),X_train.index, X_test.index,Cstar,normalisation = True\n",
    "#     # )\n",
    "# #     joblib.dump(svr_gs_tuple_out,pad/'svr_optim_rbf_rains.joblib')\n",
    "# # else:\n",
    "# #     svr_gs_tuple_out = joblib.load(pad/'svr_optim_rbf_rains.joblib')\n",
    "# fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# S1_obs_RBF = pd.concat([S1_train_SVR, S1_test_SVR])\n",
    "# DA_OL_comparison(gamma, kappa, tau, S1_obs_RBF, plot_style = 'dynamic', DA_experiment= True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gaussian processes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SEED = 1234\n",
    "# kernel = RBF(length_scale_bounds=(1e-2,1e2)) + WhiteKernel(noise_level_bounds=(1e-1,1e3))\n",
    "# gpr = GaussianProcessRegressor(kernel=kernel, n_restarts_optimizer=100, normalize_y=True, random_state = SEED)\n",
    "# gpr_pipe = make_pipeline(StandardScaler(), gpr)\n",
    "# gpr_pipe_out,r2_train,r2_test,fig,ax, S1_train_GPR, S1_test_GPR = general_sklearn_model(\n",
    "#     gpr_pipe, X_train, X_test, S1_train.values.reshape(-1,1), S1_test.values.reshape(-1,1), X_train.index, X_test.index, S1, #normalisation = True, \n",
    "#     return_predictions = True\n",
    "# )\n",
    "# fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gpr_pipe_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# S1_obs_GPR = pd.concat([S1_train_GPR, S1_test_GPR])\n",
    "# axes_gpr = (ax1_gpr, ax2_gpr, ax3_gpr, ax4_gpr)\n",
    "# delta_dict, figs, axes_gpr = DA_OL_comparison(gamma, kappa, tau, S1_obs_GPR, plot_style = 'static', DA_experiment= True, figs = figs, axes = axes_gpr, return_figures = True)\n",
    "# print(delta_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #S1 plot\n",
    "# axes_gpr[0].set_xlabel('')\n",
    "# axes_gpr[0].set_title('(b)')\n",
    "# axes_gpr[0].set_ylabel('')\n",
    "# axes_gpr[1].set_ylabel('')\n",
    "\n",
    "# ylim_S1_diff_gpr = axes_gpr[1].get_ylim()\n",
    "# ymin = min(ylim_S1_diff_gpr[0], ylim_S1_df[0])\n",
    "# ymax = max(ylim_S1_diff_gpr[1], ylim_S1_df[1])\n",
    "# axes_gpr[1].set_ylim(ymin, ymax)\n",
    "# axes[1].set_ylim(ymin, ymax)\n",
    "# display(figs[0])\n",
    "# figs[0].savefig(pad_figures_text/'S1DA_S1_comparison_LR_GPR.pdf',format = 'pdf', bbox_inches = 'tight')\n",
    "\n",
    "# #Q plot\n",
    "# axes_gpr[2].set_ylabel('')\n",
    "# axes_gpr[2].set_xlabel('')\n",
    "# axes_gpr[2].set_title('(b)')\n",
    "# axes_gpr[3].set_ylabel('')\n",
    "# ylim_Qdiff_lr = axes[3].get_ylim()\n",
    "# ylim_Qdiff_gpr = axes_gpr[3].get_ylim()\n",
    "# ymin_Qdiff = min(ylim_Qdiff_lr[0], ylim_Qdiff_gpr[0])\n",
    "# ymax_Qdiff = max(ylim_Qdiff_lr[1], ylim_Qdiff_gpr[1])\n",
    "# axes_gpr[3].set_ylim(ymin_Qdiff, ymax_Qdiff)\n",
    "# axes[3].set_ylim(ymin_Qdiff, ymax_Qdiff)\n",
    "# display(figs[1])\n",
    "# figs[1].savefig(pad_figures_text/'S1DA_Q_comparison_LR_GPR.pdf', format= 'pdf', bbox_inches = 'tight')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Old experimens only below "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# arrays = [\n",
    "#     [\"bar\", \"bar\", \"baz\", \"baz\", \"foo\", \"foo\", \"qux\", \"qux\"],\n",
    "#     [\"one\", \"two\", \"one\", \"two\", \"one\", \"two\", \"one\", \"two\"],\n",
    "# ]\n",
    "# tuples = list(zip(*arrays))\n",
    "# print(tuples)\n",
    "# index = pd.MultiIndex.from_tuples(tuples, names = ['first','second'])\n",
    "# print(index)\n",
    "# s = pd.Series(np.random.randn(8),index = index)\n",
    "# s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.arange(-30,30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def NewtonianNudging(Cstar_min, Cstar_obs, gamma, Kappa, delta_t, tau):\n",
    "#     W_t = tau_weighing(np.abs(delta_t),tau)\n",
    "#     Cstar_plus = Cstar_min + gamma*Kappa*W_t*(Cstar_obs -Cstar_min)\n",
    "#     if Cstar_plus != Cstar_min:\n",
    "#         import pdb; pdb.set_trace()\n",
    "#     return Cstar_plus\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def NN_wrapper(i, t, t_obs, t_a,Cstar,C_star_obs):\n",
    "#     if np.any(np.abs(t[i] - t_obs) < t_a):\n",
    "#         t_assimilated=t_obs[np.abs((t[i] - t_obs)) < t_a]\n",
    "#         print(\n",
    "#             f'{t[i]} should be assimilated since less than {t_a/2} rmeoved from {t_assimilated}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# C_star_updated = C_star_mod.copy()\n",
    "# for i in range(len(C_star_mod)):\n",
    "#     C_star_min = C_star_mod[i]\n",
    "#     t_mod_i = t_hour[i]\n",
    "#     t_assimilated_index = np.abs(t_mod_i - t_obs).argmin()#t_obs[np.abs((t_hour[i] - t_obs)) < t_a]\n",
    "#     t_assimilated = t_obs[t_assimilated_index]\n",
    "#     delta_t = t_mod_i - t_assimilated\n",
    "#     C_star_updated[i] = NewtonianNudging(C_star_min, Cstar_obs_lin_reg.loc[t_assimilated,:].values[0],0.5,1,delta_t,np.timedelta64(24,'h'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# t_assimilated \n",
    "# Cstar_obs_lin_reg.loc[t_assimilated,:].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# type(Cstar_obs_lin_reg.index.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd_zwalm_out = PDM(P=p_zwalm['P_thiessen'].values,\n",
    "#                        EP=ep_zwalm['EP_thiessen'].values,\n",
    "#                        t=p_zwalm['Timestamp'].values,\n",
    "#                        area=area_zwalm_new, deltat=deltat, deltatout=deltat_out,\n",
    "#                        parameters=param, m=3, DA = True, Cstar_obs = Cstar_obs_lin_reg.values.flatten(),t_obs = Cstar_obs_lin_reg.index.values, gamma = 0.5, kappa = 1,  tau = np.timedelta64(12,'h'),)\n",
    "# pd_zwalm_out_DA = pd_zwalm_out.set_index('Time')\n",
    "# pd_zwalm_out = PDM(P=p_zwalm['P_thiessen'].values,\n",
    "#                        EP=ep_zwalm['EP_thiessen'].values,\n",
    "#                        t=p_zwalm['Timestamp'].values,\n",
    "#                        area=area_zwalm_new, deltat=deltat, deltatout=deltat_out,\n",
    "#                        parameters=param, m=3, DA = False)\n",
    "# pd_zwalm_out = pd_zwalm_out.set_index('Time')\n",
    "\n",
    "# fig, ax = plt.subplots()\n",
    "# pd_zwalm_out_DA['Cstar'].plot(ylabel='[mm]', ax = ax, label = 'C* DA')\n",
    "# pd_zwalm_out['Cstar'].plot(ax = ax, label = 'C* OL')\n",
    "# ax.legend()\n",
    "# pd_zwalm_out.tail()\n",
    "\n",
    "# hvplot.extension('bokeh')\n",
    "# pd_zwalm_out_DA['Cstar'].hvplot(ylabel='[mm]',\n",
    "#     label = 'C* DA')*pd_zwalm_out['Cstar'].hvplot(label = 'C* OL')\n",
    "\n",
    "# Q_obs_daily['Value'].hvplot()\n",
    "\n",
    "# Q_obs_daily['Value'].hvplot(label = 'Observed')*pd_zwalm_out_DA[\n",
    "#     'qmodm3s'].hvplot(ylabel='[m^3/s]',label = 'DA')*pd_zwalm_out['qmodm3s'].hvplot(label = 'OL',line_dash = 'dotted', frame_width = 800, frame_height = 400)\n",
    "\n",
    "# Q_out_diff = pd_zwalm_out_DA['qmodm3s'] - pd_zwalm_out['qmodm3s']\n",
    "# Q_out_diff.hvplot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
